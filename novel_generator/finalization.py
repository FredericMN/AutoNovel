#novel_generator/finalization.py
# -*- coding: utf-8 -*-
"""
å®šç¨¿ç« èŠ‚å’Œæ‰©å†™ç« èŠ‚ï¼ˆfinalize_chapterã€enrich_chapter_textï¼‰
"""
import os
import logging
from llm_adapters import create_llm_adapter
from embedding_adapters import create_embedding_adapter
from prompt_definitions import (
    summary_prompt,
    update_character_state_prompt,
    volume_summary_prompt,  # æ–°å¢ï¼šåˆ†å·æ€»ç»“æç¤ºè¯
    resolve_global_system_prompt
)
from prompt_manager import PromptManager  # æ–°å¢ï¼šæç¤ºè¯ç®¡ç†å™¨
from novel_generator.common import invoke_with_cleaning
from utils import read_file, clear_file_content, save_string_to_txt
from novel_generator.vectorstore_utils import update_vector_store
from volume_utils import calculate_volume_ranges, is_volume_last_chapter  # æ–°å¢ï¼šåˆ†å·å·¥å…·å‡½æ•°
logging.basicConfig(
    filename='app.log',      # æ—¥å¿—æ–‡ä»¶å
    filemode='a',            # è¿½åŠ æ¨¡å¼ï¼ˆ'w' ä¼šè¦†ç›–ï¼‰
    level=logging.INFO,      # è®°å½• INFO åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
def finalize_volume(
    volume_number: int,
    volume_start: int,
    volume_end: int,
    api_key: str,
    base_url: str,
    model_name: str,
    temperature: float,
    filepath: str,
    interface_format: str,
    max_tokens: int,
    timeout: int = 600,
    use_global_system_prompt: bool = False,
    embedding_api_key: str = "",
    embedding_url: str = "",
    embedding_interface_format: str = "openai",
    embedding_model_name: str = "text-embedding-ada-002",
    gui_log_callback=None
):
    """
    ä¸ºæŒ‡å®šå·ç”Ÿæˆæ€»ç»“æ‘˜è¦ï¼ˆä»…åˆ†å·æ¨¡å¼ï¼‰

    Args:
        volume_number: å·å·ï¼ˆ1-basedï¼‰
        volume_start: å·çš„èµ·å§‹ç« èŠ‚å·
        volume_end: å·çš„ç»“æŸç« èŠ‚å·
        embedding_api_key: Embedding API Key
        embedding_url: Embedding API URL
        embedding_interface_format: Embedding æ¥å£æ ¼å¼
        embedding_model_name: Embedding æ¨¡å‹åç§°
        å…¶ä»–å‚æ•°åŒ finalize_chapter

    ç”Ÿæˆæ–‡ä»¶ï¼š
        - volume_X_summary.txt: å·æ‘˜è¦
        - æ¸…ç©º global_summary.txt ä¸ºä¸‹ä¸€å·åšå‡†å¤‡
    """
    def gui_log(msg):
        if gui_log_callback:
            gui_log_callback(msg)
        logging.info(msg)

    # åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨å®ä¾‹ï¼ˆå¸¦å¼‚å¸¸ä¿æŠ¤ï¼‰
    try:
        pm = PromptManager()
    except Exception as e:
        logging.error(f"Failed to initialize PromptManager: {e}")
        gui_log(f"âš ï¸ æç¤ºè¯ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤æç¤ºè¯: {str(e)}")

        # Fallbackå¯¹è±¡
        class FallbackPromptManager:
            def is_module_enabled(self, category, name):
                return True
            def get_prompt(self, category, name):
                return None

        pm = FallbackPromptManager()

    gui_log(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log(f"ğŸ“– å¼€å§‹ç”Ÿæˆç¬¬{volume_number}å·æ€»ç»“")
    gui_log(f"   å·èŒƒå›´: ç¬¬{volume_start}-{volume_end}ç« ")
    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")

    # è¯»å–è¯¥å·çš„æ‰€æœ‰ç« èŠ‚å†…å®¹
    chapters_dir = os.path.join(filepath, "chapters")
    volume_chapters_text = []

    gui_log(f"â–¶ è¯»å–ç¬¬{volume_start}-{volume_end}ç« å†…å®¹...")
    for chap_num in range(volume_start, volume_end + 1):
        chapter_file = os.path.join(chapters_dir, f"chapter_{chap_num}.txt")
        if os.path.exists(chapter_file):
            chapter_text = read_file(chapter_file).strip()
            if chapter_text:
                volume_chapters_text.append(f"=== ç¬¬{chap_num}ç«  ===\n{chapter_text}")
        else:
            gui_log(f"âš ï¸ ç¬¬{chap_num}ç« æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")

    if not volume_chapters_text:
        gui_log("âŒ è¯¥å·æ²¡æœ‰å¯ç”¨çš„ç« èŠ‚å†…å®¹ï¼Œæ— æ³•ç”Ÿæˆæ€»ç»“")
        logging.warning(f"Volume {volume_number} has no chapter content.")
        return

    combined_volume_text = "\n\n".join(volume_chapters_text)

    # é™åˆ¶æ€»æ–‡æœ¬é•¿åº¦ï¼ˆé¿å…è¶…è¿‡ context çª—å£ï¼‰
    max_combined_length = 150000  # çº¦150Kå­—ç¬¦
    if len(combined_volume_text) > max_combined_length:
        gui_log(f"âš ï¸ å·å†…å®¹è¿‡é•¿({len(combined_volume_text)}å­—)ï¼Œæˆªå–å{max_combined_length}å­—ç¬¦")
        combined_volume_text = combined_volume_text[-max_combined_length:]

    # è¯»å–å·æ¶æ„ä¿¡æ¯
    volume_arch_file = os.path.join(filepath, "Volume_architecture.txt")
    volume_architecture_text = ""
    if os.path.exists(volume_arch_file):
        volume_architecture_text = read_file(volume_arch_file).strip()

    # æ„å»º LLM é€‚é…å™¨
    llm_adapter = create_llm_adapter(
        interface_format=interface_format,
        base_url=base_url,
        model_name=model_name,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )
    system_prompt = resolve_global_system_prompt(use_global_system_prompt if use_global_system_prompt is not None else None)

    # ç”Ÿæˆå·æ‘˜è¦ï¼ˆä½¿ç”¨PromptManagerè·å–æç¤ºè¯ï¼‰
    gui_log("â–¶ å‘LLMå‘èµ·è¯·æ±‚ç”Ÿæˆå·æ‘˜è¦...")

    prompt_template = pm.get_prompt("finalization", "volume_summary")
    if not prompt_template:
        gui_log("   â””â”€ âš ï¸ æç¤ºè¯åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
        prompt_template = volume_summary_prompt

    volume_summary_prompt_text = prompt_template.format(
        volume_number=volume_number,
        volume_start=volume_start,
        volume_end=volume_end,
        volume_chapters_text=combined_volume_text,
        volume_architecture=volume_architecture_text
    )

    volume_summary_result = invoke_with_cleaning(
        llm_adapter,
        volume_summary_prompt_text,
        system_prompt=system_prompt
    )

    if not volume_summary_result.strip():
        gui_log("   â””â”€ âŒ ç”Ÿæˆå¤±è´¥")
        logging.warning(f"Volume {volume_number} summary generation failed.")
        return

    gui_log(f"   â””â”€ âœ… å·æ‘˜è¦ç”Ÿæˆå®Œæˆ (å…±{len(volume_summary_result)}å­—)\n")

    # ä¿å­˜å·æ‘˜è¦
    volume_summary_file = os.path.join(filepath, f"volume_{volume_number}_summary.txt")
    clear_file_content(volume_summary_file)
    save_string_to_txt(volume_summary_result, volume_summary_file)
    gui_log(f"â–¶ å·æ‘˜è¦å·²ä¿å­˜è‡³: volume_{volume_number}_summary.txt")

    # å°†å·æ‘˜è¦ä¹Ÿå­˜å…¥å‘é‡åº“ï¼ˆæ ‡è®°ä¸ºç‰¹æ®Šç±»å‹ï¼Œæ–¹ä¾¿è·¨å·æ£€ç´¢ï¼‰
    try:
        # ä½¿ç”¨ä¼ å…¥çš„ embedding é…ç½®å‚æ•°ï¼ˆå¤ç”¨ç« èŠ‚å†™å…¥çš„é…ç½®ï¼‰
        embedding_adapter = create_embedding_adapter(
            embedding_interface_format,
            embedding_api_key,
            embedding_url,
            embedding_model_name
        )

        # å…ˆåˆ é™¤æ—§çš„å·æ‘˜è¦ï¼ˆé¿å…é‡å¤å­˜å‚¨ï¼‰
        from novel_generator.vectorstore_utils import delete_volume_summary_from_store
        delete_volume_summary_from_store(embedding_adapter, filepath, volume_number)
        gui_log(f"â–¶ å·²æ¸…ç†æ—§å·æ‘˜è¦ï¼ˆå¦‚å­˜åœ¨ï¼‰")

        # å°†å·æ‘˜è¦åˆ‡åˆ†åå­˜å…¥å‘é‡åº“ï¼Œæ ‡è®°ä¸ºå·æ‘˜è¦ç±»å‹
        from novel_generator.vectorstore_utils import update_vector_store

        # æ„å»ºå·æ‘˜è¦æ ‡é¢˜ï¼ˆä¾¿äºæ£€ç´¢æ—¶è¯†åˆ«ï¼‰
        volume_summary_with_title = f"ã€ç¬¬{volume_number}å·æ€»ç»“ã€‘\n{volume_summary_result}"

        update_vector_store(
            embedding_adapter=embedding_adapter,
            new_chapter=volume_summary_with_title,
            filepath=filepath,
            chapter_num=volume_end,  # ä½¿ç”¨å·çš„æœ«ç« å·ä½œä¸ºæ ‡è®°
            volume_num=volume_number,
            doc_type="volume_summary"  # æ˜ç¡®æ ‡è®°ä¸ºå·æ‘˜è¦
        )
        gui_log(f"â–¶ å·æ‘˜è¦å·²å­˜å…¥å‘é‡åº“ï¼ˆä¾¿äºè·¨å·æ£€ç´¢ï¼‰\n")
        logging.info(f"Volume {volume_number} summary stored in vector store")
    except Exception as e:
        # éå…³é”®æ“ä½œï¼Œå¤±è´¥ä¸å½±å“ä¸»æµç¨‹
        logging.warning(f"Failed to store volume summary in vector store: {e}")
        gui_log(f"âš ï¸ å·æ‘˜è¦å‘é‡å­˜å‚¨å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {str(e)[:50]}\n")

    # æ¸…ç©ºå…¨å±€æ‘˜è¦ï¼Œä¸ºä¸‹ä¸€å·åšå‡†å¤‡
    global_summary_file = os.path.join(filepath, "global_summary.txt")
    clear_file_content(global_summary_file)
    gui_log("â–¶ å·²æ¸…ç©º global_summary.txtï¼Œä¸ºä¸‹ä¸€å·åšå‡†å¤‡\n")

    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log(f"âœ… ç¬¬{volume_number}å·æ€»ç»“å®Œæˆ")
    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    logging.info(f"Volume {volume_number} summary has been generated successfully.")


def finalize_chapter(
    novel_number: int,
    word_number: int,
    api_key: str,
    base_url: str,
    model_name: str,
    temperature: float,
    filepath: str,
    embedding_api_key: str,
    embedding_url: str,
    embedding_interface_format: str,
    embedding_model_name: str,
    interface_format: str,
    max_tokens: int,
    timeout: int = 600,
    use_global_system_prompt: bool = False,
    num_volumes: int = 0,  # æ–°å¢ï¼šåˆ†å·æ•°é‡
    total_chapters: int = 0,  # æ–°å¢ï¼šæ€»ç« èŠ‚æ•°
    gui_log_callback=None
):
    """
    å¯¹æŒ‡å®šç« èŠ‚åšæœ€ç»ˆå¤„ç†ï¼šæ›´æ–°å‰æ–‡æ‘˜è¦ã€æ›´æ–°è§’è‰²çŠ¶æ€ã€æ’å…¥å‘é‡åº“ç­‰ã€‚
    é»˜è®¤æ— éœ€å†åšæ‰©å†™æ“ä½œï¼Œè‹¥æœ‰éœ€è¦å¯åœ¨å¤–éƒ¨è°ƒç”¨ enrich_chapter_text å¤„ç†åå†å®šç¨¿ã€‚

    Returns:
        bool: å®šç¨¿æ˜¯å¦æˆåŠŸã€‚Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥ï¼ˆå¦‚ç« èŠ‚ä¸ºç©ºç­‰ï¼‰
    """
    # GUIæ—¥å¿—è¾…åŠ©å‡½æ•°
    def gui_log(msg):
        if gui_log_callback:
            gui_log_callback(msg)
        logging.info(msg)

    # åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨å®ä¾‹ï¼ˆå¸¦å¼‚å¸¸ä¿æŠ¤ï¼‰
    try:
        pm = PromptManager()
    except Exception as e:
        logging.error(f"Failed to initialize PromptManager: {e}")
        gui_log(f"âš ï¸ æç¤ºè¯ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤æç¤ºè¯: {str(e)}")

        # Fallbackå¯¹è±¡
        class FallbackPromptManager:
            def is_module_enabled(self, category, name):
                return True
            def get_prompt(self, category, name):
                return None

        pm = FallbackPromptManager()

    gui_log("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log(f"ğŸ“ å¼€å§‹å®šç¨¿ç¬¬{novel_number}ç« ")
    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")

    chapters_dir = os.path.join(filepath, "chapters")
    chapter_file = os.path.join(chapters_dir, f"chapter_{novel_number}.txt")
    chapter_text = read_file(chapter_file).strip()
    if not chapter_text:
        gui_log("âŒ ç« èŠ‚æ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•å®šç¨¿")
        logging.warning(f"Chapter {novel_number} is empty, cannot finalize.")
        return False

    llm_adapter = create_llm_adapter(
        interface_format=interface_format,
        base_url=base_url,
        model_name=model_name,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )
    system_prompt = resolve_global_system_prompt(use_global_system_prompt if use_global_system_prompt is not None else None)

    # [1/3] æ›´æ–°å‰æ–‡æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
    if pm.is_module_enabled("finalization", "summary_update"):
        gui_log(f"â–¶ [1/3] æ›´æ–°å‰æ–‡æ‘˜è¦")
        gui_log("   â”œâ”€ è¯»å–æ—§æ‘˜è¦...")
        global_summary_file = os.path.join(filepath, "global_summary.txt")
        old_global_summary = read_file(global_summary_file)

        prompt_template = pm.get_prompt("finalization", "summary_update")
        if not prompt_template:
            gui_log("   â””â”€ âš ï¸ æç¤ºè¯åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            prompt_template = summary_prompt

        prompt_summary = prompt_template.format(
            chapter_text=chapter_text,
            global_summary=old_global_summary
        )
        gui_log("   â”œâ”€ å‘LLMå‘èµ·è¯·æ±‚...")
        new_global_summary = invoke_with_cleaning(llm_adapter, prompt_summary, system_prompt=system_prompt)
        if not new_global_summary.strip():
            gui_log("   â”œâ”€ âš  ç”Ÿæˆå¤±è´¥ï¼Œä¿ç•™æ—§æ‘˜è¦")
            new_global_summary = old_global_summary
        else:
            gui_log("   â””â”€ âœ… å‰æ–‡æ‘˜è¦æ›´æ–°å®Œæˆ\n")

        clear_file_content(global_summary_file)
        save_string_to_txt(new_global_summary, global_summary_file)
    else:
        gui_log(f"â–· [1/3] æ›´æ–°å‰æ–‡æ‘˜è¦ (å·²ç¦ç”¨ï¼Œè·³è¿‡)\n")

    # [2/3] æ›´æ–°è§’è‰²çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
    if pm.is_module_enabled("finalization", "character_state_update"):
        gui_log("â–¶ [2/3] æ›´æ–°è§’è‰²çŠ¶æ€")
        gui_log("   â”œâ”€ è¯»å–æ—§çŠ¶æ€...")
        character_state_file = os.path.join(filepath, "character_state.txt")
        old_character_state = read_file(character_state_file)

        prompt_template = pm.get_prompt("finalization", "character_state_update")
        if not prompt_template:
            gui_log("   â””â”€ âš ï¸ æç¤ºè¯åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            prompt_template = update_character_state_prompt

        prompt_char_state = prompt_template.format(
            chapter_text=chapter_text,
            old_state=old_character_state
        )
        gui_log("   â”œâ”€ å‘LLMå‘èµ·è¯·æ±‚...")
        new_char_state = invoke_with_cleaning(llm_adapter, prompt_char_state, system_prompt=system_prompt)
        if not new_char_state.strip():
            gui_log("   â”œâ”€ âš  ç”Ÿæˆå¤±è´¥ï¼Œä¿ç•™æ—§çŠ¶æ€")
            new_char_state = old_character_state
        else:
            gui_log("   â””â”€ âœ… è§’è‰²çŠ¶æ€æ›´æ–°å®Œæˆ\n")

        clear_file_content(character_state_file)
        save_string_to_txt(new_char_state, character_state_file)
    else:
        gui_log(f"â–· [2/3] æ›´æ–°è§’è‰²çŠ¶æ€ (å·²ç¦ç”¨ï¼Œè·³è¿‡)\n")

    gui_log("â–¶ [3/3] æ’å…¥å‘é‡åº“")
    gui_log("   â”œâ”€ åˆ‡åˆ†ç« èŠ‚æ–‡æœ¬...")

    # è®¡ç®—å·å·ï¼ˆç”¨äºå‘é‡æ£€ç´¢ä¼˜åŒ–ï¼‰
    volume_num = None
    if num_volumes > 1 and total_chapters > 0:
        from volume_utils import get_volume_number, calculate_volume_ranges
        volume_ranges = calculate_volume_ranges(total_chapters, num_volumes)
        volume_num = get_volume_number(novel_number, volume_ranges)
        gui_log(f"   â”œâ”€ ç« èŠ‚å…ƒæ•°æ®: chapter={novel_number}, volume={volume_num}")

    update_vector_store(
        embedding_adapter=create_embedding_adapter(
            embedding_interface_format,
            embedding_api_key,
            embedding_url,
            embedding_model_name
        ),
        new_chapter=chapter_text,
        filepath=filepath,
        chapter_num=novel_number,  # æ–°å¢ï¼šç« èŠ‚å·
        volume_num=volume_num,  # æ–°å¢ï¼šå·å·
        doc_type="chapter"  # æ˜ç¡®æ ‡è®°ä¸ºç« èŠ‚
    )
    gui_log("   â””â”€ âœ… å‘é‡åº“æ›´æ–°å®Œæˆ\n")

    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log(f"âœ… ç¬¬{novel_number}ç« å®šç¨¿å®Œæˆ")
    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    logging.info(f"Chapter {novel_number} has been finalized.")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆå·æ€»ç»“ï¼ˆåˆ†å·æ¨¡å¼ + å·æœ«ç« èŠ‚ + æ¨¡å—å·²å¯ç”¨ï¼‰
    if num_volumes > 1 and total_chapters > 0 and pm.is_module_enabled("finalization", "volume_summary"):
        volume_ranges = calculate_volume_ranges(total_chapters, num_volumes)

        if is_volume_last_chapter(novel_number, volume_ranges):
            from volume_utils import get_volume_number

            volume_num = get_volume_number(novel_number, volume_ranges)
            if volume_num > 0:
                vol_start, vol_end = volume_ranges[volume_num - 1]

                gui_log(f"\nğŸ”” æ£€æµ‹åˆ°ç¬¬{novel_number}ç« æ˜¯ç¬¬{volume_num}å·çš„æœ€åä¸€ç« ")
                gui_log("   å¯åŠ¨å·æ€»ç»“ç”Ÿæˆæµç¨‹...\n")

                finalize_volume(
                    volume_number=volume_num,
                    volume_start=vol_start,
                    volume_end=vol_end,
                    api_key=api_key,
                    base_url=base_url,
                    model_name=model_name,
                    temperature=temperature,
                    filepath=filepath,
                    interface_format=interface_format,
                    max_tokens=max_tokens,
                    timeout=timeout,
                    use_global_system_prompt=use_global_system_prompt,
                    embedding_api_key=embedding_api_key,
                    embedding_url=embedding_url,
                    embedding_interface_format=embedding_interface_format,
                    embedding_model_name=embedding_model_name,
                    gui_log_callback=gui_log_callback
                )
    elif num_volumes > 1 and total_chapters > 0 and not pm.is_module_enabled("finalization", "volume_summary"):
        # å·æ€»ç»“å·²ç¦ç”¨ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å·æœ«ç« èŠ‚å¹¶æç¤º
        volume_ranges = calculate_volume_ranges(total_chapters, num_volumes)
        if is_volume_last_chapter(novel_number, volume_ranges):
            from volume_utils import get_volume_number
            volume_num = get_volume_number(novel_number, volume_ranges)
            gui_log(f"\nğŸ”” ç¬¬{novel_number}ç« æ˜¯ç¬¬{volume_num}å·çš„æœ€åä¸€ç« ")
            gui_log("   å·æ€»ç»“æ¨¡å—å·²ç¦ç”¨ï¼Œè·³è¿‡ç”Ÿæˆ\n")

    return True  # å®šç¨¿æˆåŠŸ

def enrich_chapter_text(
    chapter_text: str,
    word_number: int,
    api_key: str,
    base_url: str,
    model_name: str,
    temperature: float,
    interface_format: str,
    max_tokens: int,
    timeout: int = 600,
    use_global_system_prompt: bool = False
) -> str:
    """
    å¯¹ç« èŠ‚æ–‡æœ¬è¿›è¡Œæ‰©å†™ï¼Œä½¿å…¶æ›´æ¥è¿‘ word_number å­—æ•°ï¼Œä¿æŒå‰§æƒ…è¿è´¯ã€‚
    """
    llm_adapter = create_llm_adapter(
        interface_format=interface_format,
        base_url=base_url,
        model_name=model_name,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )
    system_prompt = resolve_global_system_prompt(use_global_system_prompt if use_global_system_prompt is not None else None)
    prompt = f"""ä»¥ä¸‹ç« èŠ‚æ–‡æœ¬è¾ƒçŸ­ï¼Œè¯·åœ¨ä¿æŒå‰§æƒ…è¿è´¯çš„å‰æä¸‹è¿›è¡Œæ‰©å†™ï¼Œä½¿å…¶æ›´å……å®ï¼Œæ¥è¿‘ {word_number} å­—å·¦å³ï¼Œä»…ç»™å‡ºæœ€ç»ˆæ–‡æœ¬ï¼Œä¸è¦è§£é‡Šä»»ä½•å†…å®¹ã€‚ï¼š
åŸå†…å®¹ï¼š
{chapter_text}
"""
    enriched_text = invoke_with_cleaning(llm_adapter, prompt, system_prompt=system_prompt)
    return enriched_text if enriched_text else chapter_text
