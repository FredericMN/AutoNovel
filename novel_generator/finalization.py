#novel_generator/finalization.py
# -*- coding: utf-8 -*-
"""
å®šç¨¿ç« èŠ‚å’Œæ‰©å†™ç« èŠ‚ï¼ˆfinalize_chapterã€enrich_chapter_textï¼‰
"""
import os
import re  # æ–°å¢ï¼šç”¨äºæå–ç²¾ç®€ç‰ˆä¼ç¬”
import logging
from core.adapters.llm_adapters import create_llm_adapter
from core.adapters.embedding_adapters import create_embedding_adapter
from core.prompting.prompt_definitions import (
    summary_prompt,
    update_character_state_prompt,
    volume_summary_prompt,  # æ–°å¢ï¼šåˆ†å·æ€»ç»“æç¤ºè¯
    plot_arcs_update_prompt,  # æ–°å¢ï¼šå‰§æƒ…è¦ç‚¹æ›´æ–°æç¤ºè¯
    plot_arcs_distill_prompt,  # æ–°å¢ï¼šå‰§æƒ…è¦ç‚¹æç‚¼æç¤ºè¯
    plot_arcs_compress_prompt,  # æ–°å¢ï¼šå‰§æƒ…è¦ç‚¹å‹ç¼©æç¤ºè¯
    resolve_global_system_prompt
)
from core.prompting.prompt_manager import PromptManager  # æ–°å¢ï¼šæç¤ºè¯ç®¡ç†å™¨
from novel_generator.common import invoke_with_cleaning
from core.utils.file_utils import read_file, clear_file_content, save_string_to_txt, get_log_file_path
from novel_generator.vectorstore_utils import update_vector_store
from core.utils.volume_utils import calculate_volume_ranges, is_volume_last_chapter  # æ–°å¢ï¼šåˆ†å·å·¥å…·å‡½æ•°
logging.basicConfig(
    filename=get_log_file_path(),      # æ—¥å¿—æ–‡ä»¶å
    filemode='a',            # è¿½åŠ æ¨¡å¼ï¼ˆ'w' ä¼šè¦†ç›–ï¼‰
    level=logging.INFO,      # è®°å½• INFO åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
def finalize_volume(
    volume_number: int,
    volume_start: int,
    volume_end: int,
    api_key: str,
    base_url: str,
    model_name: str,
    temperature: float,
    filepath: str,
    interface_format: str,
    max_tokens: int,
    timeout: int = 600,
    use_global_system_prompt: bool = False,
    embedding_api_key: str = "",
    embedding_url: str = "",
    embedding_interface_format: str = "openai",
    embedding_model_name: str = "text-embedding-ada-002",
    gui_log_callback=None
):
    """
    ä¸ºæŒ‡å®šå·ç”Ÿæˆæ€»ç»“æ‘˜è¦ï¼ˆä»…åˆ†å·æ¨¡å¼ï¼‰

    Args:
        volume_number: å·å·ï¼ˆ1-basedï¼‰
        volume_start: å·çš„èµ·å§‹ç« èŠ‚å·
        volume_end: å·çš„ç»“æŸç« èŠ‚å·
        embedding_api_key: Embedding API Key
        embedding_url: Embedding API URL
        embedding_interface_format: Embedding æ¥å£æ ¼å¼
        embedding_model_name: Embedding æ¨¡å‹åç§°
        å…¶ä»–å‚æ•°åŒ finalize_chapter

    ç”Ÿæˆæ–‡ä»¶ï¼š
        - volume_X_summary.txt: å·æ‘˜è¦
        - æ¸…ç©º global_summary.txt ä¸ºä¸‹ä¸€å·åšå‡†å¤‡
    """
    def gui_log(msg):
        if gui_log_callback:
            gui_log_callback(msg)
        logging.info(msg)

    # åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨å®ä¾‹ï¼ˆå¸¦å¼‚å¸¸ä¿æŠ¤ï¼‰
    try:
        pm = PromptManager()
    except Exception as e:
        logging.error(f"Failed to initialize PromptManager: {e}")
        gui_log(f"âš ï¸ æç¤ºè¯ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤æç¤ºè¯: {str(e)}")

        # Fallbackå¯¹è±¡
        class FallbackPromptManager:
            def is_module_enabled(self, category, name):
                return True
            def get_prompt(self, category, name):
                return None

        pm = FallbackPromptManager()

    gui_log(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log(f"ğŸ“– å¼€å§‹ç”Ÿæˆç¬¬{volume_number}å·æ€»ç»“")
    gui_log(f"   å·èŒƒå›´: ç¬¬{volume_start}-{volume_end}ç« ")
    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")

    # è¯»å–è¯¥å·çš„æ‰€æœ‰ç« èŠ‚å†…å®¹
    chapters_dir = os.path.join(filepath, "chapters")
    volume_chapters_text = []

    gui_log(f"â–¶ è¯»å–ç¬¬{volume_start}-{volume_end}ç« å†…å®¹...")
    for chap_num in range(volume_start, volume_end + 1):
        chapter_file = os.path.join(chapters_dir, f"chapter_{chap_num}.txt")
        if os.path.exists(chapter_file):
            chapter_text = read_file(chapter_file).strip()
            if chapter_text:
                volume_chapters_text.append(f"=== ç¬¬{chap_num}ç«  ===\n{chapter_text}")
        else:
            gui_log(f"âš ï¸ ç¬¬{chap_num}ç« æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")

    if not volume_chapters_text:
        gui_log("âŒ è¯¥å·æ²¡æœ‰å¯ç”¨çš„ç« èŠ‚å†…å®¹ï¼Œæ— æ³•ç”Ÿæˆæ€»ç»“")
        logging.warning(f"Volume {volume_number} has no chapter content.")
        return

    combined_volume_text = "\n\n".join(volume_chapters_text)

    # é™åˆ¶æ€»æ–‡æœ¬é•¿åº¦ï¼ˆé¿å…è¶…è¿‡ context çª—å£ï¼‰
    max_combined_length = 150000  # çº¦150Kå­—ç¬¦
    if len(combined_volume_text) > max_combined_length:
        gui_log(f"âš ï¸ å·å†…å®¹è¿‡é•¿({len(combined_volume_text)}å­—)ï¼Œæˆªå–å{max_combined_length}å­—ç¬¦")
        combined_volume_text = combined_volume_text[-max_combined_length:]

    # è¯»å–å·æ¶æ„ä¿¡æ¯
    volume_arch_file = os.path.join(filepath, "Volume_architecture.txt")
    volume_architecture_text = ""
    if os.path.exists(volume_arch_file):
        volume_architecture_text = read_file(volume_arch_file).strip()

    # æ„å»º LLM é€‚é…å™¨
    llm_adapter = create_llm_adapter(
        interface_format=interface_format,
        base_url=base_url,
        model_name=model_name,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )
    system_prompt = resolve_global_system_prompt(use_global_system_prompt if use_global_system_prompt is not None else None)

    # ç”Ÿæˆå·æ‘˜è¦ï¼ˆä½¿ç”¨PromptManagerè·å–æç¤ºè¯ï¼‰
    gui_log("â–¶ å‘LLMå‘èµ·è¯·æ±‚ç”Ÿæˆå·æ‘˜è¦...")

    prompt_template = pm.get_prompt("finalization", "volume_summary")
    if not prompt_template:
        gui_log("   â””â”€ âš ï¸ æç¤ºè¯åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
        prompt_template = volume_summary_prompt

    volume_summary_prompt_text = prompt_template.format(
        volume_number=volume_number,
        volume_start=volume_start,
        volume_end=volume_end,
        volume_chapters_text=combined_volume_text,
        volume_architecture=volume_architecture_text
    )

    volume_summary_result = invoke_with_cleaning(
        llm_adapter,
        volume_summary_prompt_text,
        system_prompt=system_prompt
    )

    if not volume_summary_result.strip():
        gui_log("   â””â”€ âŒ ç”Ÿæˆå¤±è´¥")
        logging.warning(f"Volume {volume_number} summary generation failed.")
        return

    gui_log(f"   â””â”€ âœ… å·æ‘˜è¦ç”Ÿæˆå®Œæˆ (å…±{len(volume_summary_result)}å­—)\n")

    # ä¿å­˜å·æ‘˜è¦
    volume_summary_file = os.path.join(filepath, f"volume_{volume_number}_summary.txt")
    clear_file_content(volume_summary_file)
    save_string_to_txt(volume_summary_result, volume_summary_file)
    gui_log(f"â–¶ å·æ‘˜è¦å·²ä¿å­˜è‡³: volume_{volume_number}_summary.txt")

    # ğŸ†• é™„åŠ ç²¾ç®€ç‰ˆä¼ç¬”åˆ°å·æ‘˜è¦ï¼ˆç¡®ä¿è·¨å·ä¼ç¬”æµè½¬ï¼‰
    gui_log("â–¶ æ£€æŸ¥æ˜¯å¦æœ‰ç²¾ç®€ç‰ˆä¼ç¬”éœ€è¦é™„åŠ ...")
    global_summary_file = os.path.join(filepath, "global_summary.txt")
    if os.path.exists(global_summary_file):
        global_summary = read_file(global_summary_file)

        # æå–ç²¾ç®€ç‰ˆä¼ç¬”æ®µï¼ˆä½¿ç”¨æ­£åˆ™åŒ¹é…ï¼‰
        foreshadow_match = re.search(
            r'(â”â”â” æœªè§£å†³ä¼ç¬” â”â”â”.*)',
            global_summary,
            re.DOTALL
        )

        if foreshadow_match:
            foreshadow_section = foreshadow_match.group(1).strip()

            # è¯»å–å½“å‰å·æ‘˜è¦
            current_volume_summary = read_file(volume_summary_file)

            # è¿½åŠ ä¼ç¬”åˆ°å·æ‘˜è¦æœ«å°¾
            updated_volume_summary = f"{current_volume_summary}\n\n{foreshadow_section}"

            # ä¿å­˜æ›´æ–°åçš„å·æ‘˜è¦
            clear_file_content(volume_summary_file)
            save_string_to_txt(updated_volume_summary, volume_summary_file)

            gui_log(f"   â””â”€ âœ… ç²¾ç®€ç‰ˆä¼ç¬”å·²é™„åŠ åˆ°å·æ‘˜è¦ (å…±{len(foreshadow_section)}å­—)\n")
            logging.info(f"Appended plot arcs to volume {volume_number} summary")
        else:
            gui_log("   â””â”€ âš ï¸ æœªå‘ç°ç²¾ç®€ç‰ˆä¼ç¬”æ®µï¼Œè·³è¿‡é™„åŠ \n")
    else:
        gui_log("   â””â”€ âš ï¸ global_summary.txt ä¸å­˜åœ¨ï¼Œè·³è¿‡é™„åŠ \n")

    # å°†å·æ‘˜è¦ä¹Ÿå­˜å…¥å‘é‡åº“ï¼ˆæ ‡è®°ä¸ºç‰¹æ®Šç±»å‹ï¼Œæ–¹ä¾¿è·¨å·æ£€ç´¢ï¼‰
    try:
        # ä½¿ç”¨ä¼ å…¥çš„ embedding é…ç½®å‚æ•°ï¼ˆå¤ç”¨ç« èŠ‚å†™å…¥çš„é…ç½®ï¼‰
        embedding_adapter = create_embedding_adapter(
            embedding_interface_format,
            embedding_api_key,
            embedding_url,
            embedding_model_name
        )

        # å…ˆåˆ é™¤æ—§çš„å·æ‘˜è¦ï¼ˆé¿å…é‡å¤å­˜å‚¨ï¼‰
        from novel_generator.vectorstore_utils import delete_volume_summary_from_store
        delete_volume_summary_from_store(embedding_adapter, filepath, volume_number)
        gui_log(f"â–¶ å·²æ¸…ç†æ—§å·æ‘˜è¦ï¼ˆå¦‚å­˜åœ¨ï¼‰")

        # å°†å·æ‘˜è¦åˆ‡åˆ†åå­˜å…¥å‘é‡åº“ï¼Œæ ‡è®°ä¸ºå·æ‘˜è¦ç±»å‹
        from novel_generator.vectorstore_utils import update_vector_store

        # è¯»å–æ›´æ–°åçš„å·æ‘˜è¦ï¼ˆåŒ…å«ç²¾ç®€ç‰ˆä¼ç¬”ï¼‰
        final_volume_summary = read_file(volume_summary_file)

        # æ„å»ºå·æ‘˜è¦æ ‡é¢˜ï¼ˆä¾¿äºæ£€ç´¢æ—¶è¯†åˆ«ï¼‰
        volume_summary_with_title = f"ã€ç¬¬{volume_number}å·æ€»ç»“ã€‘\n{final_volume_summary}"

        update_vector_store(
            embedding_adapter=embedding_adapter,
            new_chapter=volume_summary_with_title,
            filepath=filepath,
            chapter_num=volume_end,  # ä½¿ç”¨å·çš„æœ«ç« å·ä½œä¸ºæ ‡è®°
            volume_num=volume_number,
            doc_type="volume_summary"  # æ˜ç¡®æ ‡è®°ä¸ºå·æ‘˜è¦
        )
        gui_log(f"â–¶ å·æ‘˜è¦å·²å­˜å…¥å‘é‡åº“ï¼ˆä¾¿äºè·¨å·æ£€ç´¢ï¼‰\n")
        logging.info(f"Volume {volume_number} summary stored in vector store")
    except Exception as e:
        # éå…³é”®æ“ä½œï¼Œå¤±è´¥ä¸å½±å“ä¸»æµç¨‹
        logging.warning(f"Failed to store volume summary in vector store: {e}")
        gui_log(f"âš ï¸ å·æ‘˜è¦å‘é‡å­˜å‚¨å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰: {str(e)[:50]}\n")

    # æ¸…ç©ºå…¨å±€æ‘˜è¦ï¼Œä¸ºä¸‹ä¸€å·åšå‡†å¤‡
    global_summary_file = os.path.join(filepath, "global_summary.txt")
    clear_file_content(global_summary_file)
    gui_log("â–¶ å·²æ¸…ç©º global_summary.txtï¼Œä¸ºä¸‹ä¸€å·åšå‡†å¤‡\n")

    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log(f"âœ… ç¬¬{volume_number}å·æ€»ç»“å®Œæˆ")
    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    logging.info(f"Volume {volume_number} summary has been generated successfully.")


def finalize_chapter(
    novel_number: int,
    word_number: int,
    api_key: str,
    base_url: str,
    model_name: str,
    temperature: float,
    filepath: str,
    embedding_api_key: str,
    embedding_url: str,
    embedding_interface_format: str,
    embedding_model_name: str,
    interface_format: str,
    max_tokens: int,
    timeout: int = 600,
    use_global_system_prompt: bool = False,
    num_volumes: int = 0,  # æ–°å¢ï¼šåˆ†å·æ•°é‡
    total_chapters: int = 0,  # æ–°å¢ï¼šæ€»ç« èŠ‚æ•°
    gui_log_callback=None
):
    """
    å¯¹æŒ‡å®šç« èŠ‚åšæœ€ç»ˆå¤„ç†ï¼šæ›´æ–°å‰æ–‡æ‘˜è¦ã€æ›´æ–°è§’è‰²çŠ¶æ€ã€æ’å…¥å‘é‡åº“ç­‰ã€‚
    é»˜è®¤æ— éœ€å†åšæ‰©å†™æ“ä½œï¼Œè‹¥æœ‰éœ€è¦å¯åœ¨å¤–éƒ¨è°ƒç”¨ enrich_chapter_text å¤„ç†åå†å®šç¨¿ã€‚

    Returns:
        bool: å®šç¨¿æ˜¯å¦æˆåŠŸã€‚Trueè¡¨ç¤ºæˆåŠŸï¼ŒFalseè¡¨ç¤ºå¤±è´¥ï¼ˆå¦‚ç« èŠ‚ä¸ºç©ºç­‰ï¼‰
    """
    # GUIæ—¥å¿—è¾…åŠ©å‡½æ•°
    def gui_log(msg):
        if gui_log_callback:
            gui_log_callback(msg)
        logging.info(msg)

    # åˆ›å»ºæç¤ºè¯ç®¡ç†å™¨å®ä¾‹ï¼ˆå¸¦å¼‚å¸¸ä¿æŠ¤ï¼‰
    try:
        pm = PromptManager()
    except Exception as e:
        logging.error(f"Failed to initialize PromptManager: {e}")
        gui_log(f"âš ï¸ æç¤ºè¯ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤æç¤ºè¯: {str(e)}")

        # Fallbackå¯¹è±¡
        class FallbackPromptManager:
            def is_module_enabled(self, category, name):
                return True
            def get_prompt(self, category, name):
                return None

        pm = FallbackPromptManager()

    gui_log("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log(f"ğŸ“ å¼€å§‹å®šç¨¿ç¬¬{novel_number}ç« ")
    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")

    chapters_dir = os.path.join(filepath, "chapters")
    chapter_file = os.path.join(chapters_dir, f"chapter_{novel_number}.txt")
    chapter_text = read_file(chapter_file).strip()
    if not chapter_text:
        gui_log("âŒ ç« èŠ‚æ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•å®šç¨¿")
        logging.warning(f"Chapter {novel_number} is empty, cannot finalize.")
        return False

    llm_adapter = create_llm_adapter(
        interface_format=interface_format,
        base_url=base_url,
        model_name=model_name,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )
    system_prompt = resolve_global_system_prompt(use_global_system_prompt if use_global_system_prompt is not None else None)

    # [1/3] æ›´æ–°å‰æ–‡æ‘˜è¦ï¼ˆå¯é€‰ï¼‰
    if pm.is_module_enabled("finalization", "summary_update"):
        gui_log(f"â–¶ [1/3] æ›´æ–°å‰æ–‡æ‘˜è¦")
        gui_log("   â”œâ”€ è¯»å–æ—§æ‘˜è¦...")
        global_summary_file = os.path.join(filepath, "global_summary.txt")
        old_global_summary = read_file(global_summary_file)

        prompt_template = pm.get_prompt("finalization", "summary_update")
        if not prompt_template:
            gui_log("   â””â”€ âš ï¸ æç¤ºè¯åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            prompt_template = summary_prompt

        prompt_summary = prompt_template.format(
            chapter_text=chapter_text,
            global_summary=old_global_summary
        )
        gui_log("   â”œâ”€ å‘LLMå‘èµ·è¯·æ±‚...")
        new_global_summary = invoke_with_cleaning(llm_adapter, prompt_summary, system_prompt=system_prompt)
        if not new_global_summary.strip():
            gui_log("   â”œâ”€ âš  ç”Ÿæˆå¤±è´¥ï¼Œä¿ç•™æ—§æ‘˜è¦")
            new_global_summary = old_global_summary
        else:
            gui_log("   â””â”€ âœ… å‰æ–‡æ‘˜è¦æ›´æ–°å®Œæˆ\n")

        clear_file_content(global_summary_file)
        save_string_to_txt(new_global_summary, global_summary_file)
    else:
        gui_log(f"â–· [1/3] æ›´æ–°å‰æ–‡æ‘˜è¦ (å·²ç¦ç”¨ï¼Œè·³è¿‡)\n")

    # [2/3] æ›´æ–°è§’è‰²çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
    if pm.is_module_enabled("finalization", "character_state_update"):
        gui_log("â–¶ [2/3] æ›´æ–°è§’è‰²çŠ¶æ€")
        gui_log("   â”œâ”€ è¯»å–æ—§çŠ¶æ€...")
        character_state_file = os.path.join(filepath, "character_state.txt")
        old_character_state = read_file(character_state_file)

        prompt_template = pm.get_prompt("finalization", "character_state_update")
        if not prompt_template:
            gui_log("   â””â”€ âš ï¸ æç¤ºè¯åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            prompt_template = update_character_state_prompt

        prompt_char_state = prompt_template.format(
            chapter_text=chapter_text,
            old_state=old_character_state
        )
        gui_log("   â”œâ”€ å‘LLMå‘èµ·è¯·æ±‚...")
        new_char_state = invoke_with_cleaning(llm_adapter, prompt_char_state, system_prompt=system_prompt)
        if not new_char_state.strip():
            gui_log("   â”œâ”€ âš  ç”Ÿæˆå¤±è´¥ï¼Œä¿ç•™æ—§çŠ¶æ€")
            new_char_state = old_character_state
        else:
            gui_log("   â””â”€ âœ… è§’è‰²çŠ¶æ€æ›´æ–°å®Œæˆ\n")

        clear_file_content(character_state_file)
        save_string_to_txt(new_char_state, character_state_file)
    else:
        gui_log(f"â–· [2/3] æ›´æ–°è§’è‰²çŠ¶æ€ (å·²ç¦ç”¨ï¼Œè·³è¿‡)\n")

    # [2.5/3] æ›´æ–°å‰§æƒ…è¦ç‚¹ï¼ˆè¯¦ç»†ç‰ˆï¼‰
    if pm.is_module_enabled("finalization", "plot_arcs_update"):
        gui_log("â–¶ [2.5/3] æ›´æ–°å‰§æƒ…è¦ç‚¹ï¼ˆè¯¦ç»†ç‰ˆï¼‰")
        gui_log("   â”œâ”€ è¯»å–æ—§çš„å‰§æƒ…è¦ç‚¹...")
        plot_arcs_file = os.path.join(filepath, "plot_arcs.txt")
        old_plot_arcs = read_file(plot_arcs_file) if os.path.exists(plot_arcs_file) else ""

        prompt_template = pm.get_prompt("finalization", "plot_arcs_update")
        if not prompt_template:
            gui_log("   â””â”€ âš ï¸ æç¤ºè¯åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
            prompt_template = plot_arcs_update_prompt

        prompt_plot_arcs = prompt_template.format(
            chapter_text=chapter_text,
            old_plot_arcs=old_plot_arcs if old_plot_arcs.strip() else "ï¼ˆæš‚æ— è®°å½•ï¼‰"
        )
        gui_log("   â”œâ”€ å‘LLMå‘èµ·è¯·æ±‚...")
        new_plot_arcs = invoke_with_cleaning(llm_adapter, prompt_plot_arcs, system_prompt=system_prompt)
        if not new_plot_arcs.strip():
            gui_log("   â”œâ”€ âš  ç”Ÿæˆå¤±è´¥ï¼Œä¿ç•™æ—§å†…å®¹")
            new_plot_arcs = old_plot_arcs
        else:
            gui_log("   â””â”€ âœ… å‰§æƒ…è¦ç‚¹æ›´æ–°å®Œæˆ\n")

        clear_file_content(plot_arcs_file)
        save_string_to_txt(new_plot_arcs, plot_arcs_file)
    else:
        gui_log(f"â–· [2.5/3] æ›´æ–°å‰§æƒ…è¦ç‚¹ (å·²ç¦ç”¨ï¼Œè·³è¿‡)\n")
        new_plot_arcs = ""

    # [2.8/3] æç‚¼ä¼ç¬”åˆ°æ‘˜è¦ï¼ˆç²¾ç®€ç‰ˆï¼‰
    if pm.is_module_enabled("finalization", "plot_arcs_distill"):
        gui_log("â–¶ [2.8/3] æç‚¼ä¼ç¬”åˆ°æ‘˜è¦ï¼ˆç²¾ç®€ç‰ˆï¼‰")

        # åªæœ‰åœ¨æ­¥éª¤ 2.5 å¯ç”¨æ—¶æ‰æœ‰å†…å®¹å¯æç‚¼
        if pm.is_module_enabled("finalization", "plot_arcs_update") and new_plot_arcs.strip():
            gui_log("   â”œâ”€ ä»è¯¦ç»†ç‰ˆæç‚¼æ ¸å¿ƒä¼ç¬”...")

            prompt_template = pm.get_prompt("finalization", "plot_arcs_distill")
            if not prompt_template:
                gui_log("   â””â”€ âš ï¸ æç¤ºè¯åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æç¤ºè¯")
                prompt_template = plot_arcs_distill_prompt

            prompt_distill = prompt_template.format(plot_arcs_text=new_plot_arcs)
            gui_log("   â”œâ”€ å‘LLMå‘èµ·è¯·æ±‚...")
            distilled_arcs = invoke_with_cleaning(llm_adapter, prompt_distill, system_prompt=system_prompt)

            if distilled_arcs.strip():
                # éªŒè¯å­—æ•°
                distilled_length = len(distilled_arcs)
                gui_log(f"   â”œâ”€ ç²¾ç®€ç‰ˆå­—æ•°: {distilled_length}å­—")

                if distilled_length > 250:  # ç•™å‡º50å­—buffer
                    gui_log(f"   â”œâ”€ âš ï¸ è¶…è¿‡200å­—é™åˆ¶ï¼Œè§¦å‘äºŒæ¬¡å‹ç¼©...")

                    compress_prompt_template = pm.get_prompt("finalization", "plot_arcs_compress")
                    if not compress_prompt_template:
                        compress_prompt_template = plot_arcs_compress_prompt

                    compress_prompt = compress_prompt_template.format(distilled_arcs=distilled_arcs)
                    distilled_arcs = invoke_with_cleaning(llm_adapter, compress_prompt, system_prompt=system_prompt)

                    if distilled_arcs.strip():
                        compressed_length = len(distilled_arcs)
                        gui_log(f"   â”œâ”€ å‹ç¼©åå­—æ•°: {compressed_length}å­—")

                        # å¼ºåˆ¶æˆªæ–­ï¼ˆæç«¯æƒ…å†µï¼‰
                        if compressed_length > 200:
                            distilled_arcs = distilled_arcs[:200]
                            gui_log(f"   â”œâ”€ âš ï¸ ä»è¶…é™ï¼Œå¼ºåˆ¶æˆªæ–­åˆ°200å­—")
                    else:
                        gui_log("   â”œâ”€ âš ï¸ äºŒæ¬¡å‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨åŸç‰ˆæœ¬")

                # è¿½åŠ åˆ° global_summary.txt
                gui_log("   â”œâ”€ è¿½åŠ åˆ°å‰æ–‡æ‘˜è¦...")
                global_summary_file = os.path.join(filepath, "global_summary.txt")
                current_summary = read_file(global_summary_file) if os.path.exists(global_summary_file) else ""

                # ç§»é™¤æ—§çš„ä¼ç¬”éƒ¨åˆ†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                current_summary = re.sub(
                    r'\n*â”â”â” æœªè§£å†³ä¼ç¬” â”â”â”\n.*?(?=\n\n|$)',
                    '',
                    current_summary,
                    flags=re.DOTALL
                ).strip()

                # ç”±ç¨‹åºæ·»åŠ åˆ†éš”ç¬¦ï¼Œç¡®ä¿æ ¼å¼ç»Ÿä¸€
                formatted_foreshadow = f"â”â”â” æœªè§£å†³ä¼ç¬” â”â”â”\n{distilled_arcs.strip()}"

                # è¿½åŠ æ–°çš„ä¼ç¬”ï¼ˆå¸¦æ¢è¡Œéš”ç¦»ï¼‰
                if current_summary:
                    updated_summary = f"{current_summary}\n\n{formatted_foreshadow}"
                else:
                    updated_summary = formatted_foreshadow

                clear_file_content(global_summary_file)
                save_string_to_txt(updated_summary, global_summary_file)
                gui_log("   â””â”€ âœ… ç²¾ç®€ç‰ˆä¼ç¬”å·²èå…¥æ‘˜è¦\n")
            else:
                gui_log("   â””â”€ âš ï¸ æç‚¼å¤±è´¥ï¼Œè·³è¿‡èå…¥æ‘˜è¦\n")
        else:
            if not pm.is_module_enabled("finalization", "plot_arcs_update"):
                gui_log("   â””â”€ âš ï¸ æ­¥éª¤2.5å·²ç¦ç”¨ï¼Œæ— å†…å®¹å¯æç‚¼\n")
            else:
                gui_log("   â””â”€ âš ï¸ è¯¦ç»†ç‰ˆå‰§æƒ…è¦ç‚¹ä¸ºç©ºï¼Œè·³è¿‡æç‚¼\n")
    else:
        gui_log(f"â–· [2.8/3] æç‚¼ä¼ç¬”åˆ°æ‘˜è¦ (å·²ç¦ç”¨ï¼Œè·³è¿‡)\n")

    gui_log("â–¶ [3/3] æ’å…¥å‘é‡åº“")
    gui_log("   â”œâ”€ åˆ‡åˆ†ç« èŠ‚æ–‡æœ¬...")

    # è®¡ç®—å·å·ï¼ˆç”¨äºå‘é‡æ£€ç´¢ä¼˜åŒ–ï¼‰
    volume_num = None
    if num_volumes > 1 and total_chapters > 0:
        from core.utils.volume_utils import get_volume_number, calculate_volume_ranges
        volume_ranges = calculate_volume_ranges(total_chapters, num_volumes)
        volume_num = get_volume_number(novel_number, volume_ranges)
        gui_log(f"   â”œâ”€ ç« èŠ‚å…ƒæ•°æ®: chapter={novel_number}, volume={volume_num}")

    update_vector_store(
        embedding_adapter=create_embedding_adapter(
            embedding_interface_format,
            embedding_api_key,
            embedding_url,
            embedding_model_name
        ),
        new_chapter=chapter_text,
        filepath=filepath,
        chapter_num=novel_number,  # æ–°å¢ï¼šç« èŠ‚å·
        volume_num=volume_num,  # æ–°å¢ï¼šå·å·
        doc_type="chapter"  # æ˜ç¡®æ ‡è®°ä¸ºç« èŠ‚
    )
    gui_log("   â””â”€ âœ… å‘é‡åº“æ›´æ–°å®Œæˆ\n")

    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log(f"âœ… ç¬¬{novel_number}ç« å®šç¨¿å®Œæˆ")
    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    logging.info(f"Chapter {novel_number} has been finalized.")

    # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆå·æ€»ç»“ï¼ˆåˆ†å·æ¨¡å¼ + å·æœ«ç« èŠ‚ + æ¨¡å—å·²å¯ç”¨ï¼‰
    if num_volumes > 1 and total_chapters > 0 and pm.is_module_enabled("finalization", "volume_summary"):
        volume_ranges = calculate_volume_ranges(total_chapters, num_volumes)

        if is_volume_last_chapter(novel_number, volume_ranges):
            from core.utils.volume_utils import get_volume_number

            volume_num = get_volume_number(novel_number, volume_ranges)
            if volume_num > 0:
                vol_start, vol_end = volume_ranges[volume_num - 1]

                gui_log(f"\nğŸ”” æ£€æµ‹åˆ°ç¬¬{novel_number}ç« æ˜¯ç¬¬{volume_num}å·çš„æœ€åä¸€ç« ")
                gui_log("   å¯åŠ¨å·æ€»ç»“ç”Ÿæˆæµç¨‹...\n")

                finalize_volume(
                    volume_number=volume_num,
                    volume_start=vol_start,
                    volume_end=vol_end,
                    api_key=api_key,
                    base_url=base_url,
                    model_name=model_name,
                    temperature=temperature,
                    filepath=filepath,
                    interface_format=interface_format,
                    max_tokens=max_tokens,
                    timeout=timeout,
                    use_global_system_prompt=use_global_system_prompt,
                    embedding_api_key=embedding_api_key,
                    embedding_url=embedding_url,
                    embedding_interface_format=embedding_interface_format,
                    embedding_model_name=embedding_model_name,
                    gui_log_callback=gui_log_callback
                )
    elif num_volumes > 1 and total_chapters > 0 and not pm.is_module_enabled("finalization", "volume_summary"):
        # å·æ€»ç»“å·²ç¦ç”¨ï¼Œæ£€æŸ¥æ˜¯å¦æ˜¯å·æœ«ç« èŠ‚å¹¶æç¤º
        volume_ranges = calculate_volume_ranges(total_chapters, num_volumes)
        if is_volume_last_chapter(novel_number, volume_ranges):
            from core.utils.volume_utils import get_volume_number
            volume_num = get_volume_number(novel_number, volume_ranges)
            gui_log(f"\nğŸ”” ç¬¬{novel_number}ç« æ˜¯ç¬¬{volume_num}å·çš„æœ€åä¸€ç« ")
            gui_log("   å·æ€»ç»“æ¨¡å—å·²ç¦ç”¨ï¼Œè·³è¿‡ç”Ÿæˆ\n")

    return True  # å®šç¨¿æˆåŠŸ

def enrich_chapter_text(
    chapter_text: str,
    word_number: int,
    api_key: str,
    base_url: str,
    model_name: str,
    temperature: float,
    interface_format: str,
    max_tokens: int,
    timeout: int = 600,
    use_global_system_prompt: bool = False
) -> str:
    """
    å¯¹ç« èŠ‚æ–‡æœ¬è¿›è¡Œæ‰©å†™ï¼Œä½¿å…¶æ›´æ¥è¿‘ word_number å­—æ•°ï¼Œä¿æŒå‰§æƒ…è¿è´¯ã€‚
    """
    llm_adapter = create_llm_adapter(
        interface_format=interface_format,
        base_url=base_url,
        model_name=model_name,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )
    system_prompt = resolve_global_system_prompt(use_global_system_prompt if use_global_system_prompt is not None else None)
    prompt = f"""ä»¥ä¸‹ç« èŠ‚æ–‡æœ¬è¾ƒçŸ­ï¼Œè¯·åœ¨ä¿æŒå‰§æƒ…è¿è´¯çš„å‰æä¸‹è¿›è¡Œæ‰©å†™ï¼Œä½¿å…¶æ›´å……å®ï¼Œæ¥è¿‘ {word_number} å­—å·¦å³ï¼Œä»…ç»™å‡ºæœ€ç»ˆæ–‡æœ¬ï¼Œä¸è¦è§£é‡Šä»»ä½•å†…å®¹ã€‚ï¼š
åŸå†…å®¹ï¼š
{chapter_text}
"""
    enriched_text = invoke_with_cleaning(llm_adapter, prompt, system_prompt=system_prompt)
    return enriched_text if enriched_text else chapter_text








