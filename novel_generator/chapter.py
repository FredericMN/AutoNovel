# novel_generator/chapter.py
# -*- coding: utf-8 -*-
"""
ç« èŠ‚è‰ç¨¿ç”ŸæˆåŠè·å–å†å²ç« èŠ‚æ–‡æœ¬ã€å½“å‰ç« èŠ‚æ‘˜è¦ç­‰
"""
import os
import json
import logging
import re  # æ·»åŠ reæ¨¡å—å¯¼å…¥
from llm_adapters import create_llm_adapter
from prompt_definitions import (
    first_chapter_draft_prompt, 
    next_chapter_draft_prompt, 
    summarize_recent_chapters_prompt,
    knowledge_filter_prompt,
    knowledge_search_prompt,
    resolve_global_system_prompt
)
from chapter_directory_parser import get_chapter_info_from_blueprint
from novel_generator.common import invoke_with_cleaning
from utils import read_file, clear_file_content, save_string_to_txt
from novel_generator.vectorstore_utils import (
    get_relevant_context_from_vector_store,
    load_vector_store  # æ·»åŠ å¯¼å…¥
)
logging.basicConfig(
    filename='app.log',      # æ—¥å¿—æ–‡ä»¶å
    filemode='a',            # è¿½åŠ æ¨¡å¼ï¼ˆ'w' ä¼šè¦†ç›–ï¼‰
    level=logging.INFO,      # è®°å½• INFO åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

def get_last_n_chapters_text(chapters_dir: str, current_chapter_num: int, n: int = 3) -> list:
    """
    ä»ç›®å½• chapters_dir ä¸­è·å–æœ€è¿‘ n ç« çš„æ–‡æœ¬å†…å®¹ï¼Œè¿”å›æ–‡æœ¬åˆ—è¡¨ã€‚
    """
    texts = []
    start_chap = max(1, current_chapter_num - n)
    for c in range(start_chap, current_chapter_num):
        chap_file = os.path.join(chapters_dir, f"chapter_{c}.txt")
        if os.path.exists(chap_file):
            text = read_file(chap_file).strip()
            texts.append(text)
        else:
            texts.append("")
    return texts

def summarize_recent_chapters(
    interface_format: str,
    api_key: str,
    base_url: str,
    model_name: str,
    temperature: float,
    max_tokens: int,
    chapters_text_list: list,
    novel_number: int,            # æ–°å¢å‚æ•°
    chapter_info: dict,           # æ–°å¢å‚æ•°
    next_chapter_info: dict,      # æ–°å¢å‚æ•°
    timeout: int = 600,
    system_prompt: str = ""
) -> str:  # ä¿®æ”¹è¿”å›å€¼ç±»å‹ä¸º strï¼Œä¸å†æ˜¯ tuple
    """
    æ ¹æ®å‰ä¸‰ç« å†…å®¹ç”Ÿæˆå½“å‰ç« èŠ‚çš„ç²¾å‡†æ‘˜è¦ã€‚
    å¢å¼ºå®¹é”™:ç©ºå€¼å…œåº•ã€æ ¼å¼åŒ–å¤±è´¥é‡è¯•ã€ä½¿ç”¨ç« èŠ‚ç›®å½•ä½œä¸ºåå¤‡ã€‚
    """
    try:
        combined_text = "\n".join(chapters_text_list).strip()
        if not combined_text:
            logging.warning("No previous chapters found, using chapter directory as fallback")
            # ç©ºå€¼å…œåº•:ä½¿ç”¨ç« èŠ‚ç›®å½•ä¿¡æ¯ç”Ÿæˆç®€è¦è¯´æ˜
            chapter_info = chapter_info or {}
            return f"å½“å‰ä¸ºç¬¬{novel_number}ç« ,å‰æ–‡å°šæ— å†…å®¹ã€‚æœ¬ç« å°†å›´ç»•ã€Œ{chapter_info.get('chapter_title', 'æœªå‘½å')}ã€å±•å¼€,æ ¸å¿ƒç›®æ ‡æ˜¯{chapter_info.get('chapter_purpose', 'æ¨è¿›å‰§æƒ…')}ã€‚"

        # é™åˆ¶ç»„åˆæ–‡æœ¬é•¿åº¦
        max_combined_length = 4000
        if len(combined_text) > max_combined_length:
            combined_text = combined_text[-max_combined_length:]

        llm_adapter = create_llm_adapter(
            interface_format=interface_format,
            base_url=base_url,
            model_name=model_name,
            api_key=api_key,
            temperature=temperature,
            max_tokens=max_tokens,
            timeout=timeout
        )

        # ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½æœ‰é»˜è®¤å€¼
        chapter_info = chapter_info or {}
        next_chapter_info = next_chapter_info or {}

        prompt = summarize_recent_chapters_prompt.format(
            combined_text=combined_text,
            novel_number=novel_number,
            chapter_title=chapter_info.get("chapter_title", "æœªå‘½å"),
            chapter_role=chapter_info.get("chapter_role", "å¸¸è§„ç« èŠ‚"),
            chapter_purpose=chapter_info.get("chapter_purpose", "å†…å®¹æ¨è¿›"),
            suspense_level=chapter_info.get("suspense_level", "ä¸­ç­‰"),
            foreshadowing=chapter_info.get("foreshadowing", "æ— "),
            plot_twist_level=chapter_info.get("plot_twist_level", "â˜…â˜†â˜†â˜†â˜†"),
            chapter_summary=chapter_info.get("chapter_summary", ""),
            next_chapter_number=novel_number + 1,
            next_chapter_title=next_chapter_info.get("chapter_title", "ï¼ˆæœªå‘½åï¼‰"),
            next_chapter_role=next_chapter_info.get("chapter_role", "è¿‡æ¸¡ç« èŠ‚"),
            next_chapter_purpose=next_chapter_info.get("chapter_purpose", "æ‰¿ä¸Šå¯ä¸‹"),
            next_chapter_summary=next_chapter_info.get("chapter_summary", "è¡”æ¥è¿‡æ¸¡å†…å®¹"),
            next_chapter_suspense_level=next_chapter_info.get("suspense_level", "ä¸­ç­‰"),
            next_chapter_foreshadowing=next_chapter_info.get("foreshadowing", "æ— ç‰¹æ®Šä¼ç¬”"),
            next_chapter_plot_twist_level=next_chapter_info.get("plot_twist_level", "â˜…â˜†â˜†â˜†â˜†")
        )

        active_system_prompt = system_prompt.strip()

        # ç¬¬ä¸€æ¬¡å°è¯•ç”Ÿæˆæ‘˜è¦
        response_text = invoke_with_cleaning(
            llm_adapter,
            prompt,
            system_prompt=active_system_prompt
        )
        summary = extract_summary_from_response(response_text)

        if not summary or len(summary) < 50:
            logging.warning(f"First attempt summary too short ({len(summary) if summary else 0} chars), retrying with simplified prompt")

            # é‡è¯•:ä½¿ç”¨ç®€åŒ–çš„æç¤ºè¯
            simplified_prompt = f"""è¯·ä¸ºä»¥ä¸‹å‰æ–‡å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦(300-800å­—)ï¼š

å‰æ–‡å†…å®¹ï¼š
{combined_text}

å½“å‰è¦å†™çš„æ˜¯ç¬¬{novel_number}ç« ã€Š{chapter_info.get('chapter_title', 'æœªå‘½å')}ã€‹ã€‚

è¯·ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹,ä¸éœ€è¦ä»»ä½•å‰ç¼€æ ‡è®°ã€‚"""

            retry_response = invoke_with_cleaning(
                llm_adapter,
                simplified_prompt,
                system_prompt=active_system_prompt
            )

            # é‡è¯•å“åº”ä¹Ÿéœ€è¦ç»è¿‡æ ¼å¼æ¸…æ´—
            if retry_response:
                retry_summary = extract_summary_from_response(retry_response)
                # å¦‚æœæå–æˆåŠŸä¸”æ¯”ç¬¬ä¸€æ¬¡å¥½ï¼Œåˆ™ä½¿ç”¨é‡è¯•ç»“æœ
                if retry_summary and len(retry_summary) >= 50:
                    summary = retry_summary
                    logging.info(f"Retry successful, extracted {len(summary)} chars")
                elif retry_summary:
                    # æå–ç»“æœä»ç„¶å¤ªçŸ­ï¼Œä½†æ¯”åŸæ¥å¥½
                    summary = retry_summary
                    logging.warning(f"Retry summary still short ({len(retry_summary)} chars) but using it")
                # å¦‚æœæå–å®Œå…¨å¤±è´¥ï¼Œä¿æŒç¬¬ä¸€æ¬¡çš„ç»“æœä¸å˜
                else:
                    logging.warning("Retry extraction failed, keeping first attempt result")

        if not summary:
            logging.error("Failed to generate summary after retry, using fallback")
            # æœ€ç»ˆå…œåº•:ä½¿ç”¨ç« èŠ‚ç›®å½•ä¿¡æ¯
            fallback_summary = f"å‰æ–‡å·²å®Œæˆ{len(chapters_text_list)}ç« å†…å®¹ã€‚"
            if chapter_info.get("chapter_summary"):
                fallback_summary += f"æ¥ä¸‹æ¥ç¬¬{novel_number}ç« çš„æ ¸å¿ƒå†…å®¹æ˜¯:{chapter_info.get('chapter_summary')}"
            return fallback_summary

        return summary[:2000]  # é™åˆ¶æ‘˜è¦é•¿åº¦

    except Exception as e:
        logging.error(f"Error in summarize_recent_chapters: {str(e)}")
        # å¼‚å¸¸å…œåº•
        chapter_info = chapter_info or {}
        return f"[æ‘˜è¦ç”Ÿæˆå¼‚å¸¸] ç¬¬{novel_number}ç« ã€Š{chapter_info.get('chapter_title', 'æœªå‘½å')}ã€‹,å°†åŸºäºå‰æ–‡ç»§ç»­åˆ›ä½œã€‚"

def extract_summary_from_response(response_text: str) -> str:
    """
    ä»å“åº”æ–‡æœ¬ä¸­æå–æ‘˜è¦éƒ¨åˆ†,å¢å¼ºå®¹é”™èƒ½åŠ›

    æ”¯æŒå¤šç§æ ¼å¼:
    - æ ‡å‡†æ ¼å¼: "å½“å‰ç« èŠ‚æ‘˜è¦: xxx"
    - Markdownæ ¼å¼: "**æ‘˜è¦**: xxx" æˆ– "### æ‘˜è¦"
    - å¸¦è£…é¥°: "ã€æ‘˜è¦ã€‘xxx" æˆ– "â”â”æ‘˜è¦â”â”"
    """
    if not response_text:
        return ""

    # æ¸…ç†å¸¸è§çš„markdownæ ‡è®°
    cleaned = response_text.strip()

    # ç§»é™¤ä»£ç å—æ ‡è®°
    if cleaned.startswith("```"):
        parts = cleaned.split("```")
        if len(parts) >= 3:
            cleaned = parts[1]  # å–ä¸­é—´å†…å®¹

    # å®šä¹‰å¤šç§æ‘˜è¦æ ‡è®°,æŒ‰ä¼˜å…ˆçº§æ’åº
    summary_markers = [
        # æ ‡å‡†ä¸­æ–‡æ ‡è®°
        ("å½“å‰ç« èŠ‚æ‘˜è¦:", "å½“å‰ç« èŠ‚æ‘˜è¦ï¼š"),
        ("ç« èŠ‚æ‘˜è¦:", "ç« èŠ‚æ‘˜è¦ï¼š"),
        ("æœ¬ç« æ‘˜è¦:", "æœ¬ç« æ‘˜è¦ï¼š"),
        ("æ‘˜è¦:", "æ‘˜è¦ï¼š"),

        # Markdownæ ¼å¼
        ("**å½“å‰ç« èŠ‚æ‘˜è¦**:", "**å½“å‰ç« èŠ‚æ‘˜è¦**ï¼š"),
        ("**ç« èŠ‚æ‘˜è¦**:", "**ç« èŠ‚æ‘˜è¦**ï¼š"),
        ("**æ‘˜è¦**:", "**æ‘˜è¦**ï¼š"),
        ("### å½“å‰ç« èŠ‚æ‘˜è¦", "### ç« èŠ‚æ‘˜è¦", "### æ‘˜è¦"),
        ("## å½“å‰ç« èŠ‚æ‘˜è¦", "## ç« èŠ‚æ‘˜è¦", "## æ‘˜è¦"),

        # å¸¦è£…é¥°ç¬¦å·
        ("ã€å½“å‰ç« èŠ‚æ‘˜è¦ã€‘", "ã€ç« èŠ‚æ‘˜è¦ã€‘", "ã€æ‘˜è¦ã€‘"),
        ("â”â”å½“å‰ç« èŠ‚æ‘˜è¦â”â”", "â”â”ç« èŠ‚æ‘˜è¦â”â”", "â”â”æ‘˜è¦â”â”"),
        ("ã€Œå½“å‰ç« èŠ‚æ‘˜è¦ã€", "ã€Œç« èŠ‚æ‘˜è¦ã€", "ã€Œæ‘˜è¦ã€"),
    ]

    # å°è¯•åŒ¹é…æ‰€æœ‰æ ‡è®°
    for markers in summary_markers:
        if isinstance(markers, str):
            markers = (markers,)

        for marker in markers:
            if marker in cleaned:
                parts = cleaned.split(marker, 1)
                if len(parts) > 1:
                    extracted = parts[1].strip()

                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨æ ‡è®°
                    for end_marker in ["```", "---", "***", "â”â”â”"]:
                        if end_marker in extracted:
                            extracted = extracted.split(end_marker)[0].strip()

                    # ç§»é™¤å¼€å¤´çš„å†’å·æˆ–ç©ºç™½
                    extracted = extracted.lstrip("ï¼š: \n\t")

                    if extracted:
                        logging.info(f"Successfully extracted summary using marker: {marker}")
                        return extracted

    # å¦‚æœæ‰€æœ‰æ ‡è®°éƒ½å¤±è´¥,å°è¯•å¯å‘å¼æå–
    # 1. æŸ¥æ‰¾ç¬¬ä¸€ä¸ª"ã€‚"ä¹‹åçš„é•¿æ–‡æœ¬å—(å¯èƒ½æ˜¯æ‘˜è¦)
    lines = cleaned.split('\n')
    potential_summary = []
    found_content = False

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # è·³è¿‡æ˜æ˜¾çš„æ ‡é¢˜è¡Œ
        if line.startswith('#') or line.startswith('**'):
            continue

        # è·³è¿‡è¿‡çŸ­çš„è¡Œ(å¯èƒ½æ˜¯æ ‡é¢˜)
        if len(line) < 20:
            continue

        # æ‰¾åˆ°å®è´¨å†…å®¹
        if len(line) >= 50 and 'ã€‚' in line:
            found_content = True
            potential_summary.append(line)
        elif found_content:
            # ç»§ç»­æ”¶é›†ç›¸é‚»è¡Œ
            potential_summary.append(line)
            if len('\n'.join(potential_summary)) > 500:
                break

    if potential_summary:
        extracted = '\n'.join(potential_summary)
        logging.warning(f"Used heuristic extraction, found {len(extracted)} chars")
        return extracted

    # æœ€åå…œåº•:è¿”å›åŸæ–‡(ä¼šåœ¨è°ƒç”¨å¤„æˆªæ–­)
    logging.warning("No marker matched, returning original response")
    return cleaned

def format_chapter_info(chapter_info: dict) -> str:
    """å°†ç« èŠ‚ä¿¡æ¯å­—å…¸æ ¼å¼åŒ–ä¸ºæ–‡æœ¬"""
    template = """
ç« èŠ‚ç¼–å·ï¼šç¬¬{number}ç« 
ç« èŠ‚æ ‡é¢˜ï¼šã€Š{title}ã€‹
ç« èŠ‚å®šä½ï¼š{role}
æ ¸å¿ƒä½œç”¨ï¼š{purpose}
ä¸»è¦äººç‰©ï¼š{characters}
å…³é”®é“å…·ï¼š{items}
åœºæ™¯åœ°ç‚¹ï¼š{location}
ä¼ç¬”è®¾è®¡ï¼š{foreshadow}
æ‚¬å¿µå¯†åº¦ï¼š{suspense}
è½¬æŠ˜ç¨‹åº¦ï¼š{twist}
ç« èŠ‚ç®€è¿°ï¼š{summary}
"""
    return template.format(
        number=chapter_info.get('chapter_number', 'æœªçŸ¥'),
        title=chapter_info.get('chapter_title', 'æœªçŸ¥'),
        role=chapter_info.get('chapter_role', 'æœªçŸ¥'),
        purpose=chapter_info.get('chapter_purpose', 'æœªçŸ¥'),
        characters=chapter_info.get('characters_involved', 'æœªæŒ‡å®š'),
        items=chapter_info.get('key_items', 'æœªæŒ‡å®š'),
        location=chapter_info.get('scene_location', 'æœªæŒ‡å®š'),
        foreshadow=chapter_info.get('foreshadowing', 'æ— '),
        suspense=chapter_info.get('suspense_level', 'ä¸€èˆ¬'),
        twist=chapter_info.get('plot_twist_level', 'â˜…â˜†â˜†â˜†â˜†'),
        summary=chapter_info.get('chapter_summary', 'æœªæä¾›')
    )

def parse_search_keywords(response_text: str) -> list:
    """
    è§£ææ£€ç´¢å…³é”®è¯ï¼Œæ”¯æŒå¤šç§æ ¼å¼å¹¶æä¾›å…œåº•ç­–ç•¥

    æ ‡å‡†æ ¼å¼ï¼š'ç§‘æŠ€å…¬å¸Â·æ•°æ®æ³„éœ²\nåœ°ä¸‹å®éªŒå®¤Â·åŸºå› ç¼–è¾‘'
    å…œåº•æ”¯æŒï¼š
    - ç©ºæ ¼åˆ†éš”ï¼š"ç§‘æŠ€å…¬å¸ æ•°æ®æ³„éœ²"
    - é¡¿å·åˆ†éš”ï¼š"ç§‘æŠ€å…¬å¸ã€æ•°æ®æ³„éœ²"
    - è¿å­—ç¬¦ï¼š"ç§‘æŠ€å…¬å¸-æ•°æ®æ³„éœ²"
    - çº¯æ–‡æœ¬è¡Œï¼ˆä½œä¸ºå•ä¸ªå…³é”®è¯ç»„ï¼‰

    Returns:
        list: å…³é”®è¯ç»„åˆ—è¡¨ï¼Œæœ€å¤š5ç»„ï¼Œç©ºå“åº”è¿”å›ç©ºåˆ—è¡¨
    """
    if not response_text or not response_text.strip():
        logging.warning("parse_search_keywords: Empty response, returning empty list")
        return []

    response_text = response_text.strip()

    # ç­–ç•¥1: æ ‡å‡†æ ¼å¼ - åŒ…å«ä¸­æ–‡é—´éš”å·Â·çš„è¡Œ
    keywords = [
        line.strip().replace('Â·', ' ')
        for line in response_text.split('\n')
        if 'Â·' in line and line.strip()
    ][:5]

    if keywords:
        logging.info(f"parse_search_keywords: Extracted {len(keywords)} keywords using standard format (Â·)")
        return keywords

    # ç­–ç•¥2: å…œåº•æ ¼å¼1 - åŒ…å«å…¶ä»–åˆ†éš”ç¬¦ï¼ˆã€- : |ï¼‰
    fallback_separators = ['ã€', '-', ':', '|']
    for sep in fallback_separators:
        keywords = [
            line.strip().replace(sep, ' ')
            for line in response_text.split('\n')
            if sep in line and line.strip()
        ][:5]

        if keywords:
            logging.warning(f"parse_search_keywords: Using fallback separator '{sep}', extracted {len(keywords)} keywords")
            return keywords

    # ç­–ç•¥3: å…œåº•æ ¼å¼2 - æŒ‰è¡Œåˆ†å‰²ï¼ˆæ¯è¡Œä½œä¸ºä¸€ä¸ªå…³é”®è¯ç»„ï¼‰
    lines = [line.strip() for line in response_text.split('\n') if line.strip()]

    # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯å…³é”®è¯çš„è¡Œï¼ˆå¦‚æ ‡é¢˜ã€è¯´æ˜æ–‡å­—ï¼‰
    # æ”¾å®½é•¿åº¦é™åˆ¶ï¼Œå…è®¸2å­—ç¬¦çŸ­å…³é”®è¯ï¼ˆå¦‚"AI""VR""ç§¦æœ"ï¼‰
    valid_lines = []
    filtered_lines = []  # è®°å½•è¢«è¿‡æ»¤çš„è¡Œ

    for line in lines:
        # å…è®¸é•¿åº¦2-50çš„è¡Œ
        if not (2 <= len(line) <= 50):
            filtered_lines.append((line, "length"))
            continue

        # æ’é™¤æ˜æ˜¾çš„æ ‡é¢˜å’Œè¯´æ˜æ–‡å­—
        if line.startswith(('æ³¨', 'è¯´æ˜', 'å¤‡æ³¨', '#', '*', 'æç¤º', 'å…³é”®è¯', 'æ£€ç´¢')):
            filtered_lines.append((line, "prefix"))
            continue

        if line.endswith(('ï¼š', ':')):
            filtered_lines.append((line, "suffix"))
            continue

        valid_lines.append(line)

    # è®°å½•è¢«è¿‡æ»¤çš„è¡Œåˆ°æ—¥å¿—ï¼ˆä»…è®°å½•å‰3ä¸ªï¼Œé¿å…æ—¥å¿—è¿‡é•¿ï¼‰
    if filtered_lines:
        sample = filtered_lines[:3]
        logging.debug(f"parse_search_keywords: Filtered {len(filtered_lines)} lines, sample: {sample}")

    if valid_lines:
        keywords = valid_lines[:5]
        logging.warning(f"parse_search_keywords: Using line-based fallback, extracted {len(keywords)} keywords")
        return keywords

    # ç­–ç•¥4: æœ€ç»ˆå…œåº• - ä½¿ç”¨æ•´ä¸ªå“åº”ä½œä¸ºå•ä¸ªå…³é”®è¯ï¼ˆæˆªæ–­åˆ°åˆç†é•¿åº¦ï¼‰
    if len(response_text) <= 100:
        logging.error(f"parse_search_keywords: All parsing strategies failed, using entire response as single keyword: '{response_text[:50]}...'")
        return [response_text]
    else:
        # å“åº”è¿‡é•¿ï¼Œå¯èƒ½æ˜¯LLMè¾“å‡ºäº†æ®µè½è€Œéå…³é”®è¯ï¼Œè®°å½•é”™è¯¯å¹¶è¿”å›ç©º
        logging.error(f"parse_search_keywords: Response too long ({len(response_text)} chars) and no valid format detected. Response preview: '{response_text[:100]}...'")
        return []

def extract_chapter_numbers(text: str) -> list:
    """
    ä»æ–‡æœ¬ä¸­æå–ç« èŠ‚ç¼–å·

    æ”¯æŒæ ¼å¼ï¼š
    - ç¬¬Nç«  / ç¬¬ N ç« ï¼ˆå…è®¸ç©ºæ ¼ï¼‰
    - chapter_N / chapter N / Chapter Nï¼ˆå…è®¸ç©ºæ ¼å’Œä¸‹åˆ’çº¿ï¼Œä¸åŒºåˆ†å¤§å°å†™ï¼‰
    """
    # åŒ¹é…"ç¬¬Nç« "æ ¼å¼ï¼ˆå…è®¸ç©ºæ ¼ï¼‰
    if re.search(r'ç¬¬\s*\d+\s*ç« ', text):
        return list(map(int, re.findall(r'ç¬¬\s*(\d+)\s*ç« ', text)))

    # åŒ¹é…"chapter N"æ ¼å¼ï¼ˆå…è®¸ç©ºæ ¼/ä¸‹åˆ’çº¿ï¼Œä¸åŒºåˆ†å¤§å°å†™ï¼‰
    elif re.search(r'chapter[_\s]*\d+', text, re.IGNORECASE):
        return list(map(int, re.findall(r'chapter[_\s]*(\d+)', text, re.IGNORECASE)))

    # å…œåº•:å°è¯•æå–æ‰€æœ‰æ•°å­—ï¼ˆä½†è¦è°¨æ…ï¼Œå¯èƒ½è¯¯åŒ¹é…ï¼‰
    nums = [int(s) for s in re.findall(r'\d+', text) if s.isdigit()]
    if nums:
        logging.debug(f"extract_chapter_numbers fallback: extracted {nums} from text: {text[:50]}...")
    return nums

def apply_unified_content_rules(texts: list, current_chapter: int) -> list:
    """
    ç»Ÿä¸€çš„å†…å®¹åˆ†ç±»ä¸è§„åˆ™å¤„ç†å‡½æ•°,åˆå¹¶åŸ apply_content_rules å’Œ apply_knowledge_rules é€»è¾‘ã€‚

    Args:
        texts: å¾…å¤„ç†çš„æ–‡æœ¬åˆ—è¡¨
        current_chapter: å½“å‰ç« èŠ‚å·

    Returns:
        å¤„ç†åçš„æ–‡æœ¬åˆ—è¡¨,å¸¦æœ‰è§„åˆ™æ ‡è®°
    """
    processed = []

    for text in texts:
        # æ£€æµ‹æ˜¯å¦åŒ…å«å†å²ç« èŠ‚æ ‡è®°ï¼ˆæ›´ä¸¥æ ¼çš„æ­£åˆ™ï¼‰
        has_chapter_marker = (
            re.search(r'ç¬¬\s*\d+\s*ç« ', text) or  # "ç¬¬Nç« "æ ¼å¼ï¼Œå…è®¸ç©ºæ ¼
            re.search(r'chapter[_\s]*\d+', text, re.IGNORECASE)  # "chapter_N"æˆ–"chapter N"ï¼Œä¸åŒºåˆ†å¤§å°å†™
        )

        if has_chapter_marker:
            # æå–ç« èŠ‚ç¼–å·
            chap_nums = extract_chapter_numbers(text)

            if chap_nums:
                recent_chap = max(chap_nums)
                time_distance = current_chapter - recent_chap

                # æ ¹æ®æ—¶é—´è·ç¦»åº”ç”¨ä¸åŒè§„åˆ™
                if time_distance <= 2:
                    # è¿‘2ç« :ç›´æ¥è·³è¿‡,é˜²æ­¢é‡å¤
                    processed.append(f"[SKIP] è·³è¿‡è¿‘ç« å†…å®¹({time_distance}ç« è·ç¦»): {text[:120]}...")
                    logging.info(f"Skipped recent chapter content (distance={time_distance}): {text[:50]}...")

                elif time_distance <= 3:
                    # ç¬¬3ç« :éœ€è¦é«˜åº¦ä¿®æ”¹
                    processed.append(f"[HISTORY_LIMIT] è¿‘æœŸç« èŠ‚é™åˆ¶(éœ€ä¿®æ”¹â‰¥50%): {text[:100]}...")
                    logging.debug(f"Marked as HISTORY_LIMIT (distance={time_distance})")

                elif time_distance <= 5:
                    # 3-5ç« å‰:å…è®¸å¼•ç”¨ä½†éœ€è¦ä¿®æ”¹
                    processed.append(f"[HISTORY_REF] å†å²å‚è€ƒ(éœ€æ”¹å†™â‰¥40%): {text}")
                    logging.debug(f"Marked as HISTORY_REF (distance={time_distance})")

                else:
                    # 6ç« ä»¥å‰:å¯ä»¥å¼•ç”¨æ ¸å¿ƒæ¦‚å¿µ
                    processed.append(f"[HISTORY_OK] è¿œæœŸç« èŠ‚(å¯å¼•ç”¨æ ¸å¿ƒ): {text}")
                    logging.debug(f"Marked as HISTORY_OK (distance={time_distance})")
            else:
                # æ— æ³•æå–ç« èŠ‚å·,ä½†æœ‰ç« èŠ‚æ ‡è®°,ä¿å®ˆå¤„ç†
                processed.append(f"[HISTORY_UNKNOWN] å†å²å†…å®¹(ç« èŠ‚å·ä¸æ˜): {text[:100]}...")
                logging.warning(f"Chapter marker found but no valid chapter number: {text[:50]}...")
        else:
            # éå†å²ç« èŠ‚å†…å®¹,åˆ¤æ–­ä¸ºå¤–éƒ¨çŸ¥è¯†,ä¼˜å…ˆä½¿ç”¨
            processed.append(f"[EXTERNAL] å¤–éƒ¨çŸ¥è¯†(ä¼˜å…ˆä½¿ç”¨): {text}")
            logging.debug(f"Marked as EXTERNAL knowledge: {text[:50]}...")

    return processed

def get_filtered_knowledge_context(
    api_key: str,
    base_url: str,
    model_name: str,
    interface_format: str,
    embedding_adapter,
    filepath: str,
    chapter_info: dict,
    retrieved_texts: list,
    max_tokens: int = 2048,
    timeout: int = 600,
    system_prompt: str = ""
) -> str:
    """
    ä¼˜åŒ–åçš„çŸ¥è¯†è¿‡æ»¤å¤„ç†

    æ³¨æ„ï¼šretrieved_texts åº”è¯¥æ˜¯å·²ç»è¿‡ apply_unified_content_rules å¤„ç†çš„æ–‡æœ¬åˆ—è¡¨
    """
    if not retrieved_texts:
        return "ï¼ˆæ— ç›¸å…³çŸ¥è¯†åº“å†…å®¹ï¼‰"

    try:
        # ç›´æ¥ä½¿ç”¨å·²å¤„ç†çš„æ–‡æœ¬ï¼Œä¸å†é‡å¤è°ƒç”¨è§„åˆ™å‡½æ•°
        processed_texts = retrieved_texts

        llm_adapter = create_llm_adapter(
            interface_format=interface_format,
            base_url=base_url,
            model_name=model_name,
            api_key=api_key,
            temperature=0.3,
            max_tokens=max_tokens,
            timeout=timeout
        )

        # é™åˆ¶æ£€ç´¢æ–‡æœ¬é•¿åº¦å¹¶æ ¼å¼åŒ–
        formatted_texts = []
        max_text_length = 600
        for i, text in enumerate(processed_texts, 1):
            if len(text) > max_text_length:
                text = text[:max_text_length] + "..."
            formatted_texts.append(f"[é¢„å¤„ç†ç»“æœ{i}]\n{text}")

        # ä½¿ç”¨æ ¼å¼åŒ–å‡½æ•°å¤„ç†ç« èŠ‚ä¿¡æ¯
        formatted_chapter_info = (
            f"å½“å‰ç« èŠ‚å®šä½ï¼š{chapter_info.get('chapter_role', '')}\n"
            f"æ ¸å¿ƒç›®æ ‡ï¼š{chapter_info.get('chapter_purpose', '')}\n"
            f"å…³é”®è¦ç´ ï¼š{chapter_info.get('characters_involved', '')} | "
            f"{chapter_info.get('key_items', '')} | "
            f"{chapter_info.get('scene_location', '')}"
        )

        prompt = knowledge_filter_prompt.format(
            chapter_info=formatted_chapter_info,
            retrieved_texts="\n\n".join(formatted_texts) if formatted_texts else "ï¼ˆæ— æ£€ç´¢ç»“æœï¼‰"
        )

        filtered_content = invoke_with_cleaning(llm_adapter, prompt, system_prompt=system_prompt)
        return filtered_content if filtered_content else "ï¼ˆçŸ¥è¯†å†…å®¹è¿‡æ»¤å¤±è´¥ï¼‰"

    except TimeoutError as e:
        # è¶…æ—¶å¼‚å¸¸
        import traceback
        logging.error(f"Knowledge filtering timeout after {timeout}s: {str(e)}\n{traceback.format_exc()}")
        return "ï¼ˆçŸ¥è¯†è¿‡æ»¤è¶…æ—¶ï¼Œå»ºè®®å¢åŠ timeoutå‚æ•°æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼‰"

    except Exception as e:
        # å…¶ä»–å¼‚å¸¸ï¼šAPIè®¤è¯ã€æ¨¡å‹é”™è¯¯ã€å‚æ•°é”™è¯¯ç­‰
        import traceback
        error_msg = str(e).lower()
        error_details = traceback.format_exc()

        # è®°å½•å®Œæ•´å †æ ˆåˆ°æ—¥å¿—
        logging.error(f"Error in knowledge filtering: {str(e)}\n{error_details}")

        # æ ¹æ®é”™è¯¯ç±»å‹è¿”å›ä¸åŒæç¤º
        if "api" in error_msg and ("key" in error_msg or "auth" in error_msg or "unauthorized" in error_msg):
            return "ï¼ˆAPIè®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥api_keyé…ç½®æ˜¯å¦æ­£ç¡®ï¼‰"

        elif "connection" in error_msg or "network" in error_msg or "unreachable" in error_msg:
            return "ï¼ˆç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥base_urlå’Œç½‘ç»œçŠ¶æ€ï¼‰"

        elif "rate" in error_msg and "limit" in error_msg:
            return "ï¼ˆAPIè°ƒç”¨é¢‘ç‡è¶…é™ï¼Œè¯·ç¨åé‡è¯•æˆ–å‡çº§é…é¢ï¼‰"

        elif "model" in error_msg and ("not found" in error_msg or "invalid" in error_msg):
            return f"ï¼ˆæ¨¡å‹ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥model_nameé…ç½®: {model_name}ï¼‰"

        elif "token" in error_msg and ("limit" in error_msg or "exceed" in error_msg):
            return "ï¼ˆTokenæ•°é‡è¶…é™ï¼Œè¯·å‡å°‘max_tokensæˆ–ç®€åŒ–è¾“å…¥å†…å®¹ï¼‰"

        else:
            # æœªçŸ¥é”™è¯¯ï¼Œè¿”å›å‰100å­—ç¬¦çš„é”™è¯¯ä¿¡æ¯
            error_preview = str(e)[:100]
            return f"ï¼ˆå†…å®¹è¿‡æ»¤å‡ºé”™ï¼š{error_preview}{'...' if len(str(e)) > 100 else ''}ï¼‰"

def build_chapter_prompt(
    api_key: str,
    base_url: str,
    model_name: str,
    filepath: str,
    novel_number: int,
    word_number: int,
    temperature: float,
    user_guidance: str,
    characters_involved: str,
    key_items: str,
    scene_location: str,
    time_constraint: str,
    embedding_api_key: str,
    embedding_url: str,
    embedding_interface_format: str,
    embedding_model_name: str,
    embedding_retrieval_k: int = 2,
    interface_format: str = "openai",
    max_tokens: int = 2048,
    timeout: int = 600,
    system_prompt: str = "",
    gui_log_callback=None  # æ–°å¢GUIæ—¥å¿—å›è°ƒ
) -> str:
    """
    æ„é€ å½“å‰ç« èŠ‚çš„è¯·æ±‚æç¤ºè¯ï¼ˆå®Œæ•´å®ç°ç‰ˆï¼‰
    ä¿®æ”¹é‡ç‚¹ï¼š
    1. ä¼˜åŒ–çŸ¥è¯†åº“æ£€ç´¢æµç¨‹
    2. æ–°å¢å†…å®¹é‡å¤æ£€æµ‹æœºåˆ¶
    3. é›†æˆæç¤ºè¯åº”ç”¨è§„åˆ™
    """
    # GUIæ—¥å¿—è¾…åŠ©å‡½æ•°
    def gui_log(msg):
        if gui_log_callback:
            gui_log_callback(msg)
        logging.info(msg)

    # è¯»å–åŸºç¡€æ–‡ä»¶
    arch_file = os.path.join(filepath, "Novel_architecture.txt")
    novel_architecture_text = read_file(arch_file)
    directory_file = os.path.join(filepath, "Novel_directory.txt")
    blueprint_text = read_file(directory_file)
    global_summary_file = os.path.join(filepath, "global_summary.txt")
    global_summary_text = read_file(global_summary_file)
    character_state_file = os.path.join(filepath, "character_state.txt")
    character_state_text = read_file(character_state_file)
    
    # è·å–ç« èŠ‚ä¿¡æ¯
    chapter_info = get_chapter_info_from_blueprint(blueprint_text, novel_number)
    chapter_title = chapter_info["chapter_title"]
    chapter_role = chapter_info["chapter_role"]
    chapter_purpose = chapter_info["chapter_purpose"]
    suspense_level = chapter_info["suspense_level"]
    foreshadowing = chapter_info["foreshadowing"]
    plot_twist_level = chapter_info["plot_twist_level"]
    chapter_summary = chapter_info["chapter_summary"]

    # è·å–ä¸‹ä¸€ç« èŠ‚ä¿¡æ¯
    next_chapter_number = novel_number + 1
    next_chapter_info = get_chapter_info_from_blueprint(blueprint_text, next_chapter_number)
    next_chapter_title = next_chapter_info.get("chapter_title", "ï¼ˆæœªå‘½åï¼‰")
    next_chapter_role = next_chapter_info.get("chapter_role", "è¿‡æ¸¡ç« èŠ‚")
    next_chapter_purpose = next_chapter_info.get("chapter_purpose", "æ‰¿ä¸Šå¯ä¸‹")
    next_chapter_suspense = next_chapter_info.get("suspense_level", "ä¸­ç­‰")
    next_chapter_foreshadow = next_chapter_info.get("foreshadowing", "æ— ç‰¹æ®Šä¼ç¬”")
    next_chapter_twist = next_chapter_info.get("plot_twist_level", "â˜…â˜†â˜†â˜†â˜†")
    next_chapter_summary = next_chapter_info.get("chapter_summary", "è¡”æ¥è¿‡æ¸¡å†…å®¹")

    # åˆ›å»ºç« èŠ‚ç›®å½•
    chapters_dir = os.path.join(filepath, "chapters")
    os.makedirs(chapters_dir, exist_ok=True)

    # ç¬¬ä¸€ç« ç‰¹æ®Šå¤„ç†
    if novel_number == 1:
        return first_chapter_draft_prompt.format(
            novel_number=novel_number,
            word_number=word_number,
            chapter_title=chapter_title,
            chapter_role=chapter_role,
            chapter_purpose=chapter_purpose,
            suspense_level=suspense_level,
            foreshadowing=foreshadowing,
            plot_twist_level=plot_twist_level,
            chapter_summary=chapter_summary,
            characters_involved=characters_involved,
            key_items=key_items,
            scene_location=scene_location,
            time_constraint=time_constraint,
            user_guidance=user_guidance,
            novel_setting=novel_architecture_text
        )

    # è·å–å‰æ–‡å†…å®¹å’Œæ‘˜è¦
    recent_texts = get_last_n_chapters_text(chapters_dir, novel_number, n=3)
    
    try:
        logging.info("Attempting to generate summary")
        short_summary = summarize_recent_chapters(
            interface_format=interface_format,
            api_key=api_key,
            base_url=base_url,
            model_name=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            chapters_text_list=recent_texts,
            novel_number=novel_number,
            chapter_info=chapter_info,
            next_chapter_info=next_chapter_info,
            timeout=timeout,
            system_prompt=system_prompt
        )
        logging.info("Summary generated successfully")
    except Exception as e:
        logging.error(f"Error in summarize_recent_chapters: {str(e)}")
        short_summary = "ï¼ˆæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼‰"

    # è·å–å‰ä¸€ç« ç»“å°¾
    previous_excerpt = ""
    for text in reversed(recent_texts):
        if text.strip():
            previous_excerpt = text[-800:] if len(text) > 800 else text
            break

    # çŸ¥è¯†åº“æ£€ç´¢å’Œå¤„ç†
    try:
        gui_log("\nâ”â”â”â” çŸ¥è¯†åº“æ£€ç´¢ â”â”â”â”")
        gui_log("â–¶ å¼€å§‹å‘é‡æ£€ç´¢æµç¨‹...")

        # ç”Ÿæˆæ£€ç´¢å…³é”®è¯
        gui_log("   â”œâ”€ ç”Ÿæˆæ£€ç´¢å…³é”®è¯...")
        llm_adapter = create_llm_adapter(
            interface_format=interface_format,
            base_url=base_url,
            model_name=model_name,
            api_key=api_key,
            temperature=0.3,
            max_tokens=max_tokens,
            timeout=timeout
        )

        search_prompt = knowledge_search_prompt.format(
            chapter_number=novel_number,
            chapter_title=chapter_title,
            characters_involved=characters_involved,
            key_items=key_items,
            scene_location=scene_location,
            chapter_role=chapter_role,
            chapter_purpose=chapter_purpose,
            foreshadowing=foreshadowing,
            short_summary=short_summary,
            user_guidance=user_guidance,
            time_constraint=time_constraint
        )

        search_response = invoke_with_cleaning(llm_adapter, search_prompt, system_prompt=system_prompt)
        keyword_groups = parse_search_keywords(search_response)

        if keyword_groups:
            gui_log(f"   â”œâ”€ ç”Ÿæˆå…³é”®è¯ç»„: {len(keyword_groups)}ç»„")
            for idx, kw in enumerate(keyword_groups, 1):
                gui_log(f"       {idx}. {kw}")
        else:
            gui_log("   â”œâ”€ âš  æœªèƒ½ç”Ÿæˆå…³é”®è¯ï¼Œè·³è¿‡æ£€ç´¢")

        # æ‰§è¡Œå‘é‡æ£€ç´¢(ä½¿ç”¨å»é‡ä¼˜åŒ–çš„æ‰¹é‡æ£€ç´¢)
        from embedding_adapters import create_embedding_adapter
        from novel_generator.vectorstore_utils import get_relevant_contexts_deduplicated

        embedding_adapter = create_embedding_adapter(
            embedding_interface_format,
            embedding_api_key,
            embedding_url,
            embedding_model_name
        )

        gui_log("   â”œâ”€ æ‰§è¡Œå‘é‡æ£€ç´¢...")
        # ä½¿ç”¨æ–°çš„å»é‡æ£€ç´¢å‡½æ•°
        retrieved_docs = get_relevant_contexts_deduplicated(
            embedding_adapter=embedding_adapter,
            query_groups=keyword_groups,
            filepath=filepath,
            k_per_group=embedding_retrieval_k,
            max_total_results=embedding_retrieval_k * len(keyword_groups) if keyword_groups else 10
        )

        # è®°å½•æ£€ç´¢ç»Ÿè®¡
        from novel_generator.vectorstore_monitor import log_retrieval

        gui_log(f"   â”œâ”€ æ£€ç´¢ç»“æœ: å…±{len(retrieved_docs)}æ¡æ–‡æ¡£")

        # ç»Ÿè®¡æ–‡æ¡£ç±»å‹
        type_counts = {}
        for doc_info in retrieved_docs:
            doc_type = doc_info.get("type", "Unknown")
            type_counts[doc_type] = type_counts.get(doc_type, 0) + 1

        if type_counts:
            gui_log("   â”œâ”€ æ–‡æ¡£ç±»å‹åˆ†å¸ƒ:")
            for doc_type, count in type_counts.items():
                gui_log(f"       Â· {doc_type}: {count}æ¡")

        for keyword_group in keyword_groups:
            # ä¸ºæ¯ä¸ªå…³é”®è¯ç»„æ‰¾åˆ°æ‰€æœ‰å‘½ä¸­çš„æ–‡æ¡£
            docs_for_group = [
                {"content": d["content"], "type": d["type"]}
                for d in retrieved_docs
                if keyword_group in d.get("queries", [])
            ]
            log_retrieval(
                filepath=filepath,
                query=keyword_group,
                retrieved_docs=docs_for_group,
                chapter_number=novel_number
            )

        # æ ¼å¼åŒ–æ£€ç´¢ç»“æœ
        all_contexts = []
        for doc_info in retrieved_docs:
            content = doc_info["content"]
            doc_type = doc_info["type"]
            all_contexts.append(f"[{doc_type}] {content}")

        # åº”ç”¨ç»Ÿä¸€çš„å†…å®¹è§„åˆ™
        gui_log("   â”œâ”€ åº”ç”¨å†…å®¹è¿‡æ»¤è§„åˆ™...")
        processed_contexts = apply_unified_content_rules(all_contexts, novel_number)

        # ç»Ÿè®¡è¿‡æ»¤ç»“æœ
        skip_count = sum(1 for ctx in processed_contexts if ctx.startswith("[SKIP]"))
        external_count = sum(1 for ctx in processed_contexts if ctx.startswith("[EXTERNAL]"))
        history_count = len(processed_contexts) - skip_count - external_count

        gui_log(f"   â”œâ”€ è¿‡æ»¤ç»Ÿè®¡:")
        gui_log(f"       Â· è·³è¿‡è¿‘ç« å†…å®¹: {skip_count}æ¡")
        gui_log(f"       Â· å¤–éƒ¨çŸ¥è¯†: {external_count}æ¡")
        gui_log(f"       Â· å†å²å‚è€ƒ: {history_count}æ¡")

        # æ‰§è¡ŒçŸ¥è¯†è¿‡æ»¤
        gui_log("   â”œâ”€ LLMäºŒæ¬¡è¿‡æ»¤ä¸æ•´åˆ...")
        chapter_info_for_filter = {
            "chapter_number": novel_number,
            "chapter_title": chapter_title,
            "chapter_role": chapter_role,
            "chapter_purpose": chapter_purpose,
            "characters_involved": characters_involved,
            "key_items": key_items,
            "scene_location": scene_location,
            "foreshadowing": foreshadowing,  # ä¿®å¤æ‹¼å†™é”™è¯¯
            "suspense_level": suspense_level,
            "plot_twist_level": plot_twist_level,
            "chapter_summary": chapter_summary,
            "time_constraint": time_constraint
        }
        
        filtered_context = get_filtered_knowledge_context(
            api_key=api_key,
            base_url=base_url,
            model_name=model_name,
            interface_format=interface_format,
            embedding_adapter=embedding_adapter,
            filepath=filepath,
            chapter_info=chapter_info_for_filter,
            retrieved_texts=processed_contexts,
            max_tokens=max_tokens,
            timeout=timeout,
            system_prompt=system_prompt
        )

        # ç»Ÿè®¡æœ€ç»ˆä½¿ç”¨çš„çŸ¥è¯†
        final_length = len(filtered_context)
        gui_log(f"   â””â”€ âœ… çŸ¥è¯†æ•´åˆå®Œæˆ (è¾“å‡º{final_length}å­—)")
        gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")

    except Exception as e:
        gui_log(f"   â””â”€ âŒ çŸ¥è¯†æ£€ç´¢å¼‚å¸¸: {str(e)[:100]}")
        gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
        logging.error(f"çŸ¥è¯†å¤„ç†æµç¨‹å¼‚å¸¸ï¼š{str(e)}")
        filtered_context = "ï¼ˆçŸ¥è¯†åº“å¤„ç†å¤±è´¥ï¼‰"

    # è¿”å›æœ€ç»ˆæç¤ºè¯
    return next_chapter_draft_prompt.format(
        user_guidance=user_guidance if user_guidance else "æ— ç‰¹æ®ŠæŒ‡å¯¼",
        global_summary=global_summary_text,
        previous_chapter_excerpt=previous_excerpt,
        character_state=character_state_text,
        short_summary=short_summary,
        novel_number=novel_number,
        chapter_title=chapter_title,
        chapter_role=chapter_role,
        chapter_purpose=chapter_purpose,
        suspense_level=suspense_level,
        foreshadowing=foreshadowing,
        plot_twist_level=plot_twist_level,
        chapter_summary=chapter_summary,
        word_number=word_number,
        characters_involved=characters_involved,
        key_items=key_items,
        scene_location=scene_location,
        time_constraint=time_constraint,
        next_chapter_number=next_chapter_number,
        next_chapter_title=next_chapter_title,
        next_chapter_role=next_chapter_role,
        next_chapter_purpose=next_chapter_purpose,
        next_chapter_suspense_level=next_chapter_suspense,
        next_chapter_foreshadowing=next_chapter_foreshadow,
        next_chapter_plot_twist_level=next_chapter_twist,
        next_chapter_summary=next_chapter_summary,
        filtered_context=filtered_context
    )

def generate_chapter_draft(
    api_key: str,
    base_url: str,
    model_name: str,
    filepath: str,
    novel_number: int,
    word_number: int,
    temperature: float,
    user_guidance: str,
    characters_involved: str,
    key_items: str,
    scene_location: str,
    time_constraint: str,
    embedding_api_key: str,
    embedding_url: str,
    embedding_interface_format: str,
    embedding_model_name: str,
    embedding_retrieval_k: int = 2,
    interface_format: str = "openai",
    max_tokens: int = 2048,
    timeout: int = 600,
    custom_prompt_text: str = None,
    use_global_system_prompt: bool = False,
    gui_log_callback=None  # æ–°å¢GUIæ—¥å¿—å›è°ƒ
) -> str:
    """
    ç”Ÿæˆç« èŠ‚è‰ç¨¿ï¼Œæ”¯æŒè‡ªå®šä¹‰æç¤ºè¯
    """
    # GUIæ—¥å¿—è¾…åŠ©å‡½æ•°
    def gui_log(msg):
        if gui_log_callback:
            gui_log_callback(msg)
        logging.info(msg)

    gui_log(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log(f"ğŸ“ å¼€å§‹ç”Ÿæˆç¬¬{novel_number}ç« è‰ç¨¿")
    gui_log(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

    system_prompt = resolve_global_system_prompt(use_global_system_prompt)

    if custom_prompt_text is None:
        prompt_text = build_chapter_prompt(
            api_key=api_key,
            base_url=base_url,
            model_name=model_name,
            filepath=filepath,
            novel_number=novel_number,
            word_number=word_number,
            temperature=temperature,
            user_guidance=user_guidance,
            characters_involved=characters_involved,
            key_items=key_items,
            scene_location=scene_location,
            time_constraint=time_constraint,
            embedding_api_key=embedding_api_key,
            embedding_url=embedding_url,
            embedding_interface_format=embedding_interface_format,
            embedding_model_name=embedding_model_name,
            embedding_retrieval_k=embedding_retrieval_k,
            interface_format=interface_format,
            max_tokens=max_tokens,
            timeout=timeout,
            system_prompt=system_prompt,
            gui_log_callback=gui_log_callback  # ä¼ é€’å›è°ƒ
        )
    else:
        prompt_text = custom_prompt_text

    chapters_dir = os.path.join(filepath, "chapters")
    os.makedirs(chapters_dir, exist_ok=True)

    llm_adapter = create_llm_adapter(
        interface_format=interface_format,
        base_url=base_url,
        model_name=model_name,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )

    gui_log("   â”œâ”€ å‘LLMå‘èµ·è¯·æ±‚ç”Ÿæˆè‰ç¨¿...")
    chapter_content = invoke_with_cleaning(llm_adapter, prompt_text, system_prompt=system_prompt)
    if not chapter_content.strip():
        gui_log("   â””â”€ âš ï¸ ç”Ÿæˆå†…å®¹ä¸ºç©º")
        logging.warning("Generated chapter draft is empty.")
    else:
        gui_log(f"   â””â”€ âœ… è‰ç¨¿ç”Ÿæˆå®Œæˆ (å…±{len(chapter_content)}å­—)\n")

    chapter_file = os.path.join(chapters_dir, f"chapter_{novel_number}.txt")
    clear_file_content(chapter_file)
    save_string_to_txt(chapter_content, chapter_file)

    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    logging.info(f"[Draft] Chapter {novel_number} generated as a draft.")
    return chapter_content
