#novel_generator/architecture.py
# -*- coding: utf-8 -*-
"""
å°è¯´æ€»ä½“æ¶æ„ç”Ÿæˆï¼ˆNovel_architecture_generate åŠç›¸å…³è¾…åŠ©å‡½æ•°ï¼‰
"""
import os
import json
import logging
import traceback
from novel_generator.common import invoke_with_cleaning
from llm_adapters import create_llm_adapter
from prompt_definitions import (
    core_seed_prompt,
    character_dynamics_prompt,
    world_building_prompt,
    plot_architecture_prompt,
    create_character_state_prompt,
    resolve_global_system_prompt
)
logging.basicConfig(
    filename='app.log',      # æ—¥å¿—æ–‡ä»¶å
    filemode='a',            # è¿½åŠ æ¨¡å¼ï¼ˆ'w' ä¼šè¦†ç›–ï¼‰
    level=logging.INFO,      # è®°å½• INFO åŠä»¥ä¸Šçº§åˆ«çš„æ—¥å¿—
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
from utils import clear_file_content, save_string_to_txt

def load_partial_architecture_data(filepath: str) -> dict:
    """
    ä» filepath ä¸‹çš„ partial_architecture.json è¯»å–å·²æœ‰çš„é˜¶æ®µæ€§æ•°æ®ã€‚
    å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è§£æï¼Œè¿”å›ç©º dictã€‚
    """
    partial_file = os.path.join(filepath, "partial_architecture.json")
    if not os.path.exists(partial_file):
        return {}
    try:
        with open(partial_file, "r", encoding="utf-8") as f:
            data = json.load(f)
        return data
    except Exception as e:
        logging.warning(f"Failed to load partial_architecture.json: {e}")
        return {}

def save_partial_architecture_data(filepath: str, data: dict):
    """
    å°†é˜¶æ®µæ€§æ•°æ®å†™å…¥ partial_architecture.jsonã€‚
    """
    partial_file = os.path.join(filepath, "partial_architecture.json")
    try:
        with open(partial_file, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.warning(f"Failed to save partial_architecture.json: {e}")

def Novel_architecture_generate(
    interface_format: str,
    api_key: str,
    base_url: str,
    llm_model: str,
    topic: str,
    genre: str,
    number_of_chapters: int,
    word_number: int,
    filepath: str,
    user_guidance: str = "",  # æ–°å¢å‚æ•°
    use_global_system_prompt: bool = False,
    temperature: float = 0.7,
    max_tokens: int = 2048,
    timeout: int = 600,
    gui_log_callback=None  # æ–°å¢GUIæ—¥å¿—å›è°ƒ
) -> None:
    """
    ä¾æ¬¡è°ƒç”¨:
      1. core_seed_prompt
      2. character_dynamics_prompt
      3. world_building_prompt
      4. plot_architecture_prompt
    è‹¥åœ¨ä¸­é—´ä»»ä½•ä¸€æ­¥æŠ¥é”™ä¸”é‡è¯•å¤šæ¬¡å¤±è´¥ï¼Œåˆ™å°†å·²ç»ç”Ÿæˆçš„å†…å®¹å†™å…¥ partial_architecture.json å¹¶é€€å‡ºï¼›
    ä¸‹æ¬¡è°ƒç”¨æ—¶å¯ä»è¯¥æ­¥éª¤ç»§ç»­ã€‚
    æœ€ç»ˆè¾“å‡º Novel_architecture.txt

    æ–°å¢ï¼š
    - åœ¨å®Œæˆè§’è‰²åŠ¨åŠ›å­¦è®¾å®šåï¼Œä¾æ®è¯¥è§’è‰²ä½“ç³»ï¼Œä½¿ç”¨ create_character_state_prompt ç”Ÿæˆåˆå§‹è§’è‰²çŠ¶æ€è¡¨ï¼Œ
      å¹¶å­˜å‚¨åˆ° character_state.txtï¼Œåç»­ç»´æŠ¤æ›´æ–°ã€‚
    """
    os.makedirs(filepath, exist_ok=True)
    partial_data = load_partial_architecture_data(filepath)
    llm_adapter = create_llm_adapter(
        interface_format=interface_format,
        base_url=base_url,
        model_name=llm_model,
        api_key=api_key,
        temperature=temperature,
        max_tokens=max_tokens,
        timeout=timeout
    )
    system_prompt = resolve_global_system_prompt(use_global_system_prompt)

    # GUIæ—¥å¿—è¾…åŠ©å‡½æ•°
    def gui_log(msg):
        if gui_log_callback:
            gui_log_callback(msg)
        logging.info(msg)

    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    gui_log("ğŸ“š å¼€å§‹ç”Ÿæˆå°è¯´æ¶æ„")
    gui_log(f"   ä¸»é¢˜: {topic} | ç±»å‹: {genre}")
    gui_log(f"   ç« èŠ‚æ•°: {number_of_chapters} | æ¯ç« å­—æ•°: {word_number}")
    gui_log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")

    # Step1: æ ¸å¿ƒç§å­
    if "core_seed_result" not in partial_data:
        gui_log("â–¶ [1/5] æ ¸å¿ƒç§å­ç”Ÿæˆ")
        gui_log("   â”œâ”€ åˆ†æä¸»é¢˜ä¸ç±»å‹...")
        logging.info("Step1: Generating core_seed_prompt (æ ¸å¿ƒç§å­) ...")
        prompt_core = core_seed_prompt.format(
            topic=topic,
            genre=genre,
            number_of_chapters=number_of_chapters,
            word_number=word_number,
            user_guidance=user_guidance  # ä¿®å¤ï¼šæ·»åŠ å†…å®¹æŒ‡å¯¼
        )
        core_seed_result = invoke_with_cleaning(llm_adapter, prompt_core, system_prompt=system_prompt)
        if not core_seed_result.strip():
            logging.warning("core_seed_prompt generation failed and returned empty.")
            save_partial_architecture_data(filepath, partial_data)
            return
        partial_data["core_seed_result"] = core_seed_result
        save_partial_architecture_data(filepath, partial_data)
    else:
        logging.info("Step1 already done. Skipping...")
    # Step2: è§’è‰²åŠ¨åŠ›å­¦
    if "character_dynamics_result" not in partial_data:
        logging.info("Step2: Generating character_dynamics_prompt ...")
        prompt_character = character_dynamics_prompt.format(
            core_seed=partial_data["core_seed_result"].strip(),
            user_guidance=user_guidance
        )
        character_dynamics_result = invoke_with_cleaning(llm_adapter, prompt_character, system_prompt=system_prompt)
        if not character_dynamics_result.strip():
            logging.warning("character_dynamics_prompt generation failed.")
            save_partial_architecture_data(filepath, partial_data)
            return
        partial_data["character_dynamics_result"] = character_dynamics_result
        save_partial_architecture_data(filepath, partial_data)
    else:
        logging.info("Step2 already done. Skipping...")
    # ç”Ÿæˆåˆå§‹è§’è‰²çŠ¶æ€
    if "character_dynamics_result" in partial_data and "character_state_result" not in partial_data:
        logging.info("Generating initial character state from character dynamics ...")
        prompt_char_state_init = create_character_state_prompt.format(
            character_dynamics=partial_data["character_dynamics_result"].strip()
        )
        character_state_init = invoke_with_cleaning(llm_adapter, prompt_char_state_init, system_prompt=system_prompt)
        if not character_state_init.strip():
            logging.warning("create_character_state_prompt generation failed.")
            save_partial_architecture_data(filepath, partial_data)
            return
        partial_data["character_state_result"] = character_state_init
        character_state_file = os.path.join(filepath, "character_state.txt")
        clear_file_content(character_state_file)
        save_string_to_txt(character_state_init, character_state_file)
        save_partial_architecture_data(filepath, partial_data)
        logging.info("Initial character state created and saved.")
    # Step3: ä¸–ç•Œè§‚
    if "world_building_result" not in partial_data:
        logging.info("Step3: Generating world_building_prompt ...")
        prompt_world = world_building_prompt.format(
            core_seed=partial_data["core_seed_result"].strip(),
            user_guidance=user_guidance  # ä¿®å¤ï¼šæ·»åŠ ç”¨æˆ·æŒ‡å¯¼
        )
        world_building_result = invoke_with_cleaning(llm_adapter, prompt_world, system_prompt=system_prompt)
        if not world_building_result.strip():
            logging.warning("world_building_prompt generation failed.")
            save_partial_architecture_data(filepath, partial_data)
            return
        partial_data["world_building_result"] = world_building_result
        save_partial_architecture_data(filepath, partial_data)
    else:
        logging.info("Step3 already done. Skipping...")
    # Step4: ä¸‰å¹•å¼æƒ…èŠ‚
    if "plot_arch_result" not in partial_data:
        logging.info("Step4: Generating plot_architecture_prompt ...")
        prompt_plot = plot_architecture_prompt.format(
            core_seed=partial_data["core_seed_result"].strip(),
            character_dynamics=partial_data["character_dynamics_result"].strip(),
            world_building=partial_data["world_building_result"].strip(),
            user_guidance=user_guidance  # ä¿®å¤ï¼šæ·»åŠ ç”¨æˆ·æŒ‡å¯¼
        )
        plot_arch_result = invoke_with_cleaning(llm_adapter, prompt_plot, system_prompt=system_prompt)
        if not plot_arch_result.strip():
            logging.warning("plot_architecture_prompt generation failed.")
            save_partial_architecture_data(filepath, partial_data)
            return
        partial_data["plot_arch_result"] = plot_arch_result
        save_partial_architecture_data(filepath, partial_data)
    else:
        logging.info("Step4 already done. Skipping...")

    core_seed_result = partial_data["core_seed_result"]
    character_dynamics_result = partial_data["character_dynamics_result"]
    world_building_result = partial_data["world_building_result"]
    plot_arch_result = partial_data["plot_arch_result"]

    final_content = (
        "#=== 0) å°è¯´è®¾å®š ===\n"
        f"ä¸»é¢˜ï¼š{topic},ç±»å‹ï¼š{genre},ç¯‡å¹…ï¼šçº¦{number_of_chapters}ç« ï¼ˆæ¯ç« {word_number}å­—ï¼‰\n\n"
        "#=== 1) æ ¸å¿ƒç§å­ ===\n"
        f"{core_seed_result}\n\n"
        "#=== 2) è§’è‰²åŠ¨åŠ›å­¦ ===\n"
        f"{character_dynamics_result}\n\n"
        "#=== 3) ä¸–ç•Œè§‚ ===\n"
        f"{world_building_result}\n\n"
        "#=== 4) ä¸‰å¹•å¼æƒ…èŠ‚æ¶æ„ ===\n"
        f"{plot_arch_result}\n"
    )

    arch_file = os.path.join(filepath, "Novel_architecture.txt")
    clear_file_content(arch_file)
    save_string_to_txt(final_content, arch_file)
    logging.info("Novel_architecture.txt has been generated successfully.")

    partial_arch_file = os.path.join(filepath, "partial_architecture.json")
    if os.path.exists(partial_arch_file):
        os.remove(partial_arch_file)
        logging.info("partial_architecture.json removed (all steps completed).")
